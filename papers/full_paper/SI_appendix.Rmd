---
title             : "Supplementary information:Predicting information integration in pragmatic word learning across development"
shorttitle        : "Supplementary information"

author: 
  - name          : "Manuel Bohn"
    affiliation   : "1,2"
    address       : "Department of Psychology, 450 Serra Mall, Stanford, CA 94305"
    email         : "bohn@stanford.edu"
  - name          : "Michael Henry Tessler"
    affiliation   : "3"
  - name          : "Megan Merrick"
    affiliation   : "1"
  - name          : "Michael C. Frank"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Stanford University"
  - id            : "2"
    institution   : "Leipzig Research Center for Early Child Development, Leipzig University"
  - id            : "3"
    institution   : "Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology"

bibliography      : ["library.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : no

class             : "doc"
output            : papaja::apa6_pdf
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F, include = T)
library(papaja)
library(tidyverse)
library(knitr)
library(ggthemes)
library(langcog)
library(rwebppl)
library(coda)
library(matrixStats)
library(ggpubr)
library(lme4)
library(broom)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}

```


```{r}
# load data files

# adults exp 1 
adult_ex1_data <- read_csv(file="../../stats/data/adult_ex1.csv")
# adults exp 2 novelty
adult_ex2_novelty_data <- read_csv(file="../../stats/data/adult_ex2_novelty.csv")
# adults exp 2 preference
adult_ex2_preference_data <- read_csv(file="../../stats/data/adult_ex2_preference.csv")
# adults ex3
adult_ex3_data <-read_csv(file="../../stats/data/adult_ex3.csv")
# prior strength manipulation experiments in experiment 4
adult_ex4_prior_data <-read_csv(file="../../stats/data/adult_ex4_prior.csv") 
# adults ex4
adult_ex4_data <-read_csv(file="../../stats/data/adult_ex4.csv") 

# children ex1
child_ex1_data <-read_csv(file="../../stats/data/child_ex1.csv")
# children ex2 preference
child_ex2_data <-read_csv(file="../../stats/data/child_ex2.csv") 
# children ex3
child_ex3_data <-read_csv(file="../../stats/data/child_ex3.csv") 
```


# Structure

Here we present details for the cognitive models as well as supplementary analysis and results. Readers who are interested in the model or analysis code itself are encouraged to consult the corresponding online repository: (https://github.com/manuelbohn/mcc).  

# Models

All models were computed in WebPPL [@dippl] using the r package `rwebppl` [@R-rwebppl].

## Pragmatics model

The pragmatics model had the same basic structure as the model in Frank and Goodman [-@frank2014inferring]. It captures the following process: A pragmatic listener ($L_1$) reasons about a pragmatic speaker ($S_1$) who is reasoning about a naive listener ($L_0$) who interprets utterances according to their literal semantics. The outcome is the posterior probability of a particular referent given an utterance. According to Bayes rule it is defined as:

\begin{equation} 
P_{L_1}(r_s|u)\propto P_{S_1}(u|r_s)P_{S_i}(r_s)
\end{equation} 


The right side of this equation has two components, the likelihood $P_{S1}(u|r_s)$ and the prior $P_{S_i}(r_s)$. The likelihood represent the probability that a particular utterance is used to refer to the referent. It is defined in terms of a utility function $U_S(u;s)$:

\begin{equation} 
P_{S_1}(u|r_s)\propto exp(\alpha U_{S_1}(u;s))
\end{equation} 

This utility is defined as the surprisal of $u$ for a literal listener, $L_0$:

\begin{equation} 
U_{S_1}(r_s) = logL_0(r_s|u)
\end{equation} 

The literal listener computes the probability of $r_s$ according to its literal semantics. In our case, all objects (and their names) were new to the listener. That is, $L_0$ could not rely on the semantics of the utterance to discriminate between referents. However, the utterance also included the agents turn to one of the tables. The semantics of turning to one of the tables is roughly equal to using a word that could be used to describe the objects on that table. In addition to the utterance, $L_0$ also takes in the prior probability of the referent given the speaker. It is therefore defined as:

\begin{equation} 
P_{L0}(r_s|u)\propto [\![u]\!](r_s)P_{S_i}(r_s)
\end{equation} 

Now, $S_1$ is assumed to choose the utterance that yields the highest utility for $L_0$. This captures the idea that speakers are trying to communicate in an informative way.

As noted in the paper, the parameter $\alpha$ (speaker optimality parameter) in equation 2  determines the absolute strength of the likelihood term. It's interpretation is *how* rational $L_1$ thinks $S_1$ is in this particular context. For adults, we used the data from Experiment 1 to infer the value of $\alpha$. That is, we inferred which value of $\alpha$ would generate model predictions for the RSA model described above (assuming equal prior probability for each object) that corresponded to the average proportion of correct responses measured in Experiment 1. This value was then used for $\alpha$ in Experiment 3.

For children, the speaker optimality parameter changed with age. Instead of inferring a single value across age, we used the data from Experiment 5 to find the slope and intercept that best described the developmental trajectory in the data. As for adults, this was done via the RSA model with equal prior probability for each object. In Experiment 7, the speaker optimality parameter for a given child of a given age was computed by taking the overall intercept and adding the slope times the child's age (with age anchored at 0).

The prior distribution over objects, $P_{S_i}(r_s)$, varied with the common ground manipulation, the identity of the speaker (indicated by subscript *i*) and the alignment of utterance and common ground information. Numerically, it depended on the measurement obtained in Experiment 2A and B for adults and Experiment 6 for children. 

For adults, this worked in the following way. For example, in Experiment 2, for the preference/same speaker condition, when the speaker indicated that they liked object A and disliked object B, the average proportion with which participants chose object A was `r adult_ex2_preference_data %>% filter(condition == "same_speaker") %>% summarise(mean = mean(correct)) %>% pull(mean)` and for object B it was `r 1-adult_ex2_preference_data %>% filter(condition == "same_speaker") %>% summarise(mean = mean(correct)) %>% pull(mean)` respectively. In Experiment 3, this measurement determined the prior distribution over objects in cases whenever the the same manipulation was used (preference/same speaker). When utterance and common ground information were aligned (i.e. object A was the more informative object), the distribution of objects was (A,B,B). The corresponding prior distribution was therefore (`r adult_ex2_preference_data %>% filter(condition == "same_speaker") %>% summarise(mean = mean(correct)) %>% pull(mean)`, `r 1-adult_ex2_preference_data %>% filter(condition == "same_speaker") %>% summarise(mean = mean(correct)) %>% pull(mean)`, `r 1-adult_ex2_preference_data %>% filter(condition == "same_speaker") %>% summarise(mean = mean(correct)) %>% pull(mean)`). When information sources were dis-aligned (i.e. object B was the more informative one), the object distribution was (B,A,A) and the prior distribution was (`r 1-adult_ex2_preference_data %>% filter(condition == "same_speaker") %>% summarise(mean = mean(correct)) %>% pull(mean)`, `r adult_ex2_preference_data %>% filter(condition == "same_speaker") %>% summarise(mean = mean(correct)) %>% pull(mean)`, `r adult_ex2_preference_data %>% filter(condition == "same_speaker") %>% summarise(mean = mean(correct)) %>% pull(mean)`). Note that Experiment 3 involved three objects while Experiment 2 only involved two. We nevertheless used the exact proportions measured in Experiment 2 for each object to inform the prior. This approach spread out the absolute probability mass but conserved the relative relation between objects.

For children, we used the data from Experiment 6 to model the slope and intercept that best described the developmental trajectory in the data for each of the two conditions (see online repository for corresponding code). As for the speaker optimality parameter, this allowed us to generate prior distributions that were sensitive to the child's age. In Experiment 7, the prior probability for an object was computed by taking the intercept for the respective condition (same or different speaker), adding the slope times the child's age and then using a logistic transformation to convert the outcome into proportions. The overall distribution then depended on the alignment of information sources in the same way as it did for adults. 

## Prior only model

The prior only model ignored the information about the intended referent that was expressed by the utterance and instead only focused on  common ground manipulation. It is defined as: 

\begin{equation} 
P_{L1}(r_s|u)\propto P_{S_i}(r_s)
\end{equation} 

That is, the probability of the referent given the utterance is determined by the prior probability of the referent for a particular speaker. The prior distributions were set in the same way as for the pragmatics model.

## Flat prior model

This model was identical in structure to the pragmatics model with the exception that the prior distribution did not correspond to the measurements from Experiment 2 and did not vary with speaker identity. That is, regardless of common ground manipulation and speaker identity the prior distribution was always uniform (e.g. 0.33,0.33,0.33). This was the case for children as well as  adults. The speaker optimality parameter was set in the same way as in the pragmatics model. 

# Experiment 4 

## Prior strength manipualtions

```{r ex4 prior pre-tests data adults}
# load data from prior strength manipulation experiments to set priors
adult_ex4_prior_data <-read_csv(file="../../stats/data/adult_ex4_prior.csv") 
```

```{r table_prior,results = "asis"}
ex4_prior_models <- adult_ex4_prior_data %>%
  group_by(common_ground_manipulation,prior_manipulation)%>%
  do(models = glmer(correct ~ speaker + (1|id) + (1|agent),data = .,family=binomial,  control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5))))


ex4_prior_models_table <- tidy(ex4_prior_models, models)%>%
  filter(group == "fixed")%>%
  select(-statistic, -group)%>%
  mutate(p.value = ifelse(p.value<.001,"< .001",as.character(paste("=",substr(round(p.value,3),2,5),sep=" "))),
         std.error = round(std.error,2),
         estimate = round(estimate,2),
         term = case_when(term == "(Intercept)" ~ "Intercept",
                          term == "speakersame_speaker" ~ "condition (same speaker)"))%>%
  rename(Manipulation = common_ground_manipulation,
         Strength = prior_manipulation,
         Term = term,
         Estimate = estimate,
         SE = std.error,
         p = p.value)

apa_table(
  ex4_prior_models_table
  , caption = "Model output for prior strength experiments "
  , note = "Model structure in all cases: correct ~ condition + (1|id) + (1|agent)"
  , escape = T
)
```

Below we describe the different ways in which prior strength was manipulated. The corresponding experiments can be found in the online repository. The test event was always the same: The animal disappeared and then either the same or a different animal returned and requested an object using an unknown word.

For preference, both tables initially contained an object. In preference/strong the animal turned to one side and stated that they liked (“Oh wow, I really like that one”) or disliked (“Oh bleh, I really don’t like that one”) the object. Then they turned the other side and expressed the respective other attitude. In preference/medium the animal only turned to one side and expressed liking in a more subtle way (saying only: “Oh, wow”). 

For novelty, one table was empty while there was an object on the other. In novelty/strong the animal turned to one of the sides and commented either on the presence (“Aha, look at that”) or the absence of an object (“Hm, nothing there”). Then the animal turned to the other side and commented in a complementary way. Next, the animal disappeared. The same animal re-appeared and the sequence above was repeated. When the animal disappeared for the second time, a second object appeared on the empty table while the animal was away. In novelty/medium, the animal commented on the presence/absence of objects in the same way but did so only once. In novelty/weak, the animal only turned to the present object and commented on it. 

In all cases, the order of utterances and/or the side to which the speaker turned first were counterbalanced. Figure \ref{fig:priorplot} shows the results for the same speaker and different speaker conditions for each manipulation.

```{r priorplot, fig.cap = "Results from prior strength manipulation Experiments. Transparent dots show data from individual participants, diamonds represent condition means, error bars are 95\\% CIs. Dashed line indicates performance expected by chance.", fig.height = 3}

p_adult_ex4_priors <- adult_ex4_prior_data%>%
  mutate(prior_manipulation = relevel(as.factor(prior_manipulation), ref = "strong"))%>%
  group_by(common_ground_manipulation,prior_manipulation,speaker, id) %>%
  summarise(correct = mean(correct))
  

p_adult_ex4_priors_ci <- p_adult_ex4_priors %>%
  multi_boot_standard(col = "correct")

ggplot() +
  geom_jitter(data = p_adult_ex4_priors, aes(x = speaker, y = correct, col = speaker), alpha = 0.3, width = .3,height = .02)+
  geom_pointrange(data = p_adult_ex4_priors_ci, aes(x = speaker, y = mean, col = speaker,ymin = ci_lower, ymax = ci_upper),size = .8, pch = 5, fatten = 2.5)+
  geom_hline(yintercept = 0.5, lty=2)+
  labs(x="",y="")+
  facet_grid(common_ground_manipulation ~ prior_manipulation)+
  theme_few() + 
  ylim(-0.05,1.05)+
  guides(alpha = F,size =F)+
  scale_color_solarized()+
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(), legend.position = "right")
```

Table \ref{tab:table_prior} shows the results of a generalized linear mixed model (GLMM), fir to the data from each manipulation. The results show that the parameter estimates for condition (i.e. difference between same speaker and different speaker condition) decreases in line with the hypothesized effect of the prior manipulation. 

## Model predictions

Figure \ref{fig:modelpredex4} compares model predictions to the data from Experiment 4. 

```{r modelpredex4, include = T, fig.cap = "Correlation plot for model predictions and data from Experiment 4. All models included a noise parameter. Coefficients and p-values are based on Pearson correlation statistics. Dots represent condition modes. Error bars represent 95\\% HDIs.", fig.height=2.5}

adult_ex4_data_summary <- adult_ex4_data %>%
  mutate(prior_manipulation = relevel(as.factor(prior_manipulation), ref = "strong"))%>%
  mutate(model = "data") %>%
  group_by(model,common_ground_manipulation,prior_manipulation,speaker,alignment)%>%
  summarize(k = sum(correct_inf), n = n())%>%
  ungroup() %>%
  mutate(a = 1 + k,
         b = 1 + n - k,
         ci_lower  = qbeta(.025, a, b),
         ci_upper = qbeta(.975, a, b),
         mean = (a-1)/(a+b-2))%>%
  select(-a,-b,-n,-k)

# summarize model predictions

ex4_flat_prior_model_pred_noise <- readRDS("../../stats/saves/ex4_flat_prior_model_noise.rds") %>%
  filter(!(Parameter %in% c("noise")))  %>%
  separate(Parameter, into = c("common_ground_manipulation","prior_manipulation","speaker", "alignment"), sep="/")%>%
  mutate(model="flat_prior_noise")%>%
  group_by(model,common_ground_manipulation,prior_manipulation,speaker,alignment)%>%
  summarise(mean = estimate_mode(value), 
            ci_lower = hdi_lower(value),
            ci_upper = hdi_upper(value))

ex4_prior_only_model_pred_noise <- readRDS("../../stats/saves/ex4_prior_only_model_noise.rds") %>%
  filter(!(Parameter %in% c("noise")))  %>%
  separate(Parameter, into = c("common_ground_manipulation","prior_manipulation","speaker", "alignment"), sep="/")%>%
  mutate(model="prior_only_noise")%>%
  group_by(model,common_ground_manipulation,prior_manipulation,speaker,alignment)%>%
  summarise(mean = estimate_mode(value), 
            ci_lower = hdi_lower(value),
            ci_upper = hdi_upper(value))

ex4_pragm_model_pred_noise <- readRDS("../../stats/saves/ex4_pragm_model_noise.rds") %>%
  filter(!(Parameter %in% c("noise")))  %>%
  separate(Parameter, into = c("common_ground_manipulation","prior_manipulation","speaker", "alignment"), sep="/")%>%
  mutate(model="pragmatic_noise")%>%
  group_by(model,common_ground_manipulation,prior_manipulation,speaker,alignment)%>%
  summarise(mean = estimate_mode(value), 
            ci_lower = hdi_lower(value),
            ci_upper = hdi_upper(value))


ex_4_model_pred <- bind_rows(
  ex4_pragm_model_pred_noise,
  ex4_prior_only_model_pred_noise,
  ex4_flat_prior_model_pred_noise
)%>%
  ungroup()%>%
  mutate(prior_manipulation = relevel(as.factor(prior_manipulation), ref = "strong"))
 
# combine model predictions and data

ex_4_pred <- bind_rows(
  ex_4_model_pred,
  adult_ex4_data_summary
)

ex_4_cor_plot <- ex_4_pred %>%
  ungroup()%>%
  filter(model != "data") %>%
  left_join(., ex_4_pred %>%
    ungroup()%>%
    filter(model == "data") %>%
    rename(data_mean = mean, data_ci_lower = ci_lower, data_ci_upper = ci_upper) %>%
    select(-model)
  )%>%
  mutate(model =  case_when(model == "pragmatic_noise" ~ "Pragmatics",
                            model == "prior_only_noise" ~ "Prior only",
                            model == "flat_prior_noise" ~ "Flat prior"
                            ))


ggplot(data = ex_4_cor_plot,aes(x = mean, y = data_mean, col = prior_manipulation)) +
  geom_abline(intercept = 0, slope = 1, lty = 2, alpha = 0.7, size = 0.5)+
  geom_point(size = 2)+
  geom_errorbar(aes(ymin = data_ci_lower, ymax = data_ci_upper),width = 0,size = .7)+
  geom_errorbarh(aes(xmin = ci_lower, xmax = ci_upper), height = 0,size = .7)+
  coord_fixed()+
  xlim(0,1)+ylim(0,1)+
  xlab("Model")+
  ylab("Data")+
  facet_grid ( ~ model) +
  stat_cor(method = "pearson", label.x = 0.01, label.y = 0.99, aes(x = mean, y = data_mean), inherit.aes = F, size = 3)+
  theme_few(base_size = ) + 
  scale_colour_ptol(name = "Prior strength")+
  theme(legend.position = "right")

```

# Model comparison

Analysis code for model comparison can be found in the online repository.

## Experiment 3

Here we report details on the model comparisons based on marginal log-likelihoods of the data for each model. Bayes Factors were computed by first subtracting log-likelihoods and then exponentiating the result. Table \ref{tab:ex3_comp} shows Bayes Factors for model comparisons in Experiment 3. We did not pre-register the inclusion of the noise parameter for Experiment 4. The first row in Table \ref{tab:ex3_comp}

```{r ex3_comp,results = "asis"}
log_like_pragmatic_ex3 <- readRDS("../../stats/saves/ex3_pragm_model_loglike.rds")

ex3_pragm_model_noise_loglike <- readRDS("../../stats/saves/ex3_pragm_model_noise_loglike.rds")%>%
  mutate(model = "pragmatic_noise")%>%
  group_by(model)%>%
  summarize(logP = logSumExp(value))

ex3_prior_only_model_noise_loglike <- readRDS("../../stats/saves/ex3_prior_only_model_noise_loglike.rds")%>%
  mutate(model = "prior_only_noise")%>%
  group_by(model)%>%
  summarize(logP = logSumExp(value))

ex3_flat_prior_model_noise_loglike <- readRDS("../../stats/saves/ex3_flat_prior_model_noise_loglike.rds")%>%
  mutate(model = "flat_prior_noise")%>%
  group_by(model)%>%
  summarize(logP = logSumExp(value))

ex3_model_comparison <- bind_rows(
  log_like_pragmatic_ex3,
  ex3_pragm_model_noise_loglike,
  ex3_flat_prior_model_noise_loglike,
  ex3_prior_only_model_noise_loglike
)%>%
  mutate(model = reorder(model,logP))

ex3_bf <- bind_rows(
  log_like_pragmatic_ex3,
  ex3_pragm_model_noise_loglike,
  ex3_flat_prior_model_noise_loglike,
  ex3_prior_only_model_noise_loglike
) %>% spread(model, logP) %>%
  mutate("pragmatic_noise > pragmatic" = exp(pragmatic_noise - pragmatic),
         "pragmatic_noise > prior_only_noise" = exp(pragmatic_noise - prior_only_noise),
         "pragmatic_noise > flat_prior_noise" = exp(pragmatic_noise - flat_prior_noise),
         "prior_only_noise > flat_prior_noise" = exp(prior_only_noise - flat_prior_noise)) %>%
  select(-pragmatic,-pragmatic_noise, -flat_prior_noise, -prior_only_noise)%>%
  gather(Comparison, BF)%>%
  mutate(BF = formatC(BF,2))

apa_table(
  ex3_bf
  , caption = "Bayes Factors for model comparisons in Experiment 3"
  , escape = T
)

```

Figure \ref{fig:ex3noise} shows the posterior distribution of the noise parameter for each model. The noise parameter was fit to the data and indicates the proportion of responses that are estimated to be due to random rather than in line with model predictions. That is, a model that makes predictions that are closer to the data is likely to have a lower noise parameter. 

```{r ex3noise, fig.cap = "Posterior distribution of noise parameter for each model in Experiment 3", fig.height = 2}
ex3_noise_parameters <- bind_rows(
  readRDS("../../stats/saves/ex3_pragm_model_noise.rds") %>%
  filter(Parameter %in% c("noise"))  %>%
  mutate(Model = "Pragmatics"),
  readRDS("../../stats/saves/ex3_prior_only_model_noise.rds") %>%
  filter(Parameter %in% c("noise"))  %>%
  mutate(Model = "Prior only"),
  readRDS("../../stats/saves/ex3_flat_prior_model_noise.rds") %>%
  filter(Parameter %in% c("noise"))  %>%
  mutate(Model = "Flat prior")
  )

ggplot(ex3_noise_parameters, aes(x = value, col = Model, fill = Model))+
  geom_density(alpha = .5)+
  theme_few()+
  xlab("Noise parameter")+
  xlim(0,1)+
  scale_color_manual(breaks=c("Pragmatics","Prior only","Flat prior"),
                    values= c("#b58900","#6c71c4","#859900"))+
  scale_fill_manual(breaks=c("Pragmatics","Prior only","Flat prior"),
                    values= c("#b58900","#6c71c4","#859900"))
```

## Experiment 4

Table \ref{tab:ex4_comp} shows Bayes Factors for model comparisons in Experiment 3. As pre-registered, all models included a noise parameter.

```{r ex4_comp, results="asis"}
ex4_pragm_model_noise_loglike <- readRDS("../../stats/saves/ex4_pragm_model_noise_loglike.rds")%>%
  mutate(model = "pragmatic_noise")%>%
  group_by(model)%>%
  summarize(logP = logSumExp(value))

ex4_prior_only_model_noise_loglike <- readRDS("../../stats/saves/ex4_prior_only_model_noise_loglike.rds")%>%
  mutate(model = "prior_only_noise")%>%
  group_by(model)%>%
  summarize(logP = logSumExp(value))

ex4_flat_prior_model_noise_loglike <- readRDS("../../stats/saves/ex4_flat_prior_model_noise_loglike.rds")%>%
  mutate(model = "flat_prior_noise")%>%
  group_by(model)%>%
  summarize(logP = logSumExp(value))

ex4_bf <- bind_rows(
  ex4_pragm_model_noise_loglike,
  ex4_flat_prior_model_noise_loglike,
  ex4_prior_only_model_noise_loglike
) %>% spread(model, logP) %>%
  mutate("Pragmatics > Prior only" = exp(pragmatic_noise - prior_only_noise),
         "Pragmatics > Flat prior" = exp(pragmatic_noise - flat_prior_noise),
         "Flat prior > Prior only" = exp(flat_prior_noise - prior_only_noise)) %>%
  select(-pragmatic_noise, -flat_prior_noise, -prior_only_noise)%>%
  gather(Comparison, BF)%>%
  mutate(BF = formatC(BF,2))

apa_table(
  ex4_bf
  , caption = "Model comparisons in Experiment 3"
  , note = "BF = Bayes Factor; All models include a noise parameter."
  , escape = T
)


```

Figure \ref{fig:ex4noise} shows the posterior distribution of the noise parameter for each model in Experiment 4.

```{r ex4noise, include = T, fig.cap = "Posterior distribution of noise parameter for each model in Experiment 3", fig.height = 2}
ex4_noise_parameters <- bind_rows(
  readRDS("../../stats/saves/ex4_pragm_model_noise.rds") %>%
  filter(Parameter %in% c("noise"))  %>%
  mutate(Model = "Pragmatics"),
  readRDS("../../stats/saves/ex4_prior_only_model_noise.rds") %>%
  filter(Parameter %in% c("noise"))  %>%
  mutate(Model = "Prior only"),
  readRDS("../../stats/saves/ex4_flat_prior_model_noise.rds") %>%
  filter(Parameter %in% c("noise"))  %>%
  mutate(Model = "Flat prior")
  )

ggplot(ex4_noise_parameters, aes(x = value, col = Model, fill = Model))+
  geom_density(alpha = .5)+
  theme_few()+
  xlab("Noise parameter")+
  xlim(0,1)+
  scale_color_manual(breaks=c("Pragmatics","Prior only","Flat prior"),
                    values= c("#b58900","#6c71c4","#859900"))+
  scale_fill_manual(breaks=c("Pragmatics","Prior only","Flat prior"),
                    values= c("#b58900","#6c71c4","#859900"))
```

## Experiment 7

For children, we compared models using different types of noise parameters. We preregistered the model comparison for models including a single noise parameter. We added the additional model comparisons because the noise parameter was comparably high. The additional model comparisons allow us to see if the pragmatics model provides a better fit when the more emphasis is put on the model structure itself. The results show that this was the case.

Parameter free models did not include a noise parameter. Noise models included a single noise parameter across age. Developmental noise models included a noise parameter that changed with age. That is, instead of a single value, we inferred an intercept and a slope for the noise parameter. Noise was therefore a function of the child's age. Table \ref{tab:child_prag_bf} shows model comparisons for the pragmatics models using different noise parameters. This shows that including a noise parameter improves model fit but that the type of noise parameter does not make much of a difference.  

```{r child_prag_bf, results = "asis"}
child_ex3_model_comparison <- readRDS("../../stats/saves/child_ex3_model_comparison.rds")

child_ex3_pragmatic_models_bf <- child_ex3_model_comparison%>%
  filter(model == "pragmatic")%>%
  spread(parameter, logP) %>%
  mutate("dev. noise > noise" = exp(`developmental noise` - noise),
         "noise > parameter free" = exp(noise - `parameter free`),
         "dev. noise > parameter free" = exp(`developmental noise` - `parameter free`)) %>%
  select(-model,-`parameter free`,-`developmental noise`, -noise)%>%
  gather(Comparison, BF)%>%
  mutate(BF = formatC(BF,2))

apa_table(
  child_ex3_pragmatic_models_bf
  , caption = "Model comparisons for pragmatics models in Experiment 7"
  , note = "BF = Bayes Factor"
  , escape = T
)

```

Table \ref{tab:child_bf} shows results for model comparison for the different types of noise parameters. In any case, the pragmatics model provides a substantially better fit to the data compared to the alternative models

```{r child_bf, results = "asis"}
child_ex3_bf <- child_ex3_model_comparison%>%
  rename(Parameter = parameter)%>%
  group_by(Parameter)%>%
  spread(model, logP) %>%
  mutate("Pragmatics > Flat P." = formatC(exp(pragmatic - flat_prior),2),
         "Pragmatics > P. only" = formatC(exp(pragmatic - prior_only),2),
         "Flat P. > P. only" = formatC(exp(flat_prior - prior_only),2)) %>%
  select(-pragmatic,-flat_prior, -prior_only)

apa_table(
  child_ex3_bf
  , caption = "Model comparisons in Experiment 7"
  , note = "BF = Bayes Factor"
  , escape = T
)

```

```{r}
child_noise_parameters <- bind_rows(
  readRDS("../../stats/saves/child_ex3_pragm_model_noise.rds") %>%
  filter(Parameter %in% c("noise"))  %>%
  mutate(Model = "Pragmatics"),
  readRDS("../../stats/saves/child_ex3_prior_only_model_noise.rds") %>%
  filter(Parameter %in% c("noise"))  %>%
  mutate(Model = "Prior only"),
  readRDS("../../stats/saves/child_ex3_flat_prior_model_noise.rds") %>%
  filter(Parameter %in% c("noise"))  %>%
  mutate(Model = "Flat prior")
  )

child_noise_plot <- ggplot(child_noise_parameters, aes(x = value, col = Model, fill = Model))+
  geom_density(alpha = .5)+
  theme_few()+
  xlab("Noise parameter")+
  xlim(0,1)+
  scale_color_manual(breaks=c("Pragmatics","Prior only","Flat prior"),
                    values= c("#b58900","#6c71c4","#859900"))+
  scale_fill_manual(breaks=c("Pragmatics","Prior only","Flat prior"),
                    values= c("#b58900","#6c71c4","#859900"))
```

```{r, include = T}

child_ex3_pragm_model_developmental_noise_param <- readRDS("../../stats/saves/child_ex3_pragm_model_developmental_noise.rds") %>%
  filter(Parameter %in% c("noise_int","noise_slope"))  %>%
  group_by(Parameter)%>%
  summarise(mean = estimate_mode(value), 
            ci_lower = hdi_lower(value),
            ci_upper = hdi_upper(value))

child_ex3_prior_only_model_developmental_noise_param <- readRDS("../../stats/saves/child_ex3_prior_only_model_developmental_noise.rds") %>%
  filter(Parameter %in% c("noise_int","noise_slope"))  %>%
  group_by(Parameter)%>%
  summarise(mean = estimate_mode(value), 
            ci_lower = hdi_lower(value),
            ci_upper = hdi_upper(value))


child_ex3_flat_prior_model_developmental_noise_param <- readRDS("../../stats/saves/child_ex3_flat_prior_model_developmental_noise.rds") %>%
  filter(Parameter %in% c("noise_int","noise_slope"))  %>%
  group_by(Parameter)%>%
  summarise(mean = estimate_mode(value), 
            ci_lower = hdi_lower(value),
            ci_upper = hdi_upper(value))

developmental_noise_parameter <- data_frame(
  age = rep(seq(0,2, by = 0.05),3),
  Model = c(rep("Pragmatics",41),
            rep("Flat prior",41),
            rep("Prior only",41)),
  int = c(rep(child_ex3_pragm_model_developmental_noise_param%>%
                filter(Parameter == "noise_int")%>%
                pull(mean),41),
          rep(child_ex3_flat_prior_model_developmental_noise_param%>%
                filter(Parameter == "noise_int")%>%
                pull(mean),41),
          rep(child_ex3_prior_only_model_developmental_noise_param%>%
                filter(Parameter == "noise_int")%>%
                pull(mean),41)
          ),
  slope = c(rep(child_ex3_pragm_model_developmental_noise_param%>%
                filter(Parameter == "noise_slope")%>%
                pull(mean),41),
          rep(child_ex3_flat_prior_model_developmental_noise_param%>%
                filter(Parameter == "noise_slope")%>%
                pull(mean),41),
          rep(child_ex3_prior_only_model_developmental_noise_param%>%
                filter(Parameter == "noise_slope")%>%
                pull(mean),41))
) %>%
  mutate(y = plogis(int + slope *age),
         age = age +3)

child_dev_noise_plot <- ggplot(developmental_noise_parameter, aes(x = age, y= y, col = Model))+
  geom_line(size = 1)+
  ylab("Noise parameter")+
  xlab("Age")+
  ylim(0,1)+
  theme_few()+
  scale_color_manual(breaks=c("Pragmatics","Prior only","Flat prior"),
                    values= c("#b58900","#6c71c4","#859900"))
```

Figure \ref{fig:childnoise} shows the different types of noise parameters for the each model. Figure \ref{fig:childnoise}A shows that the pragmatics model has the lowest estimated level of noise of all the models considered. Figure \ref{fig:childnoise}B shows that the the pragmatics model has the lowest level of estimated noise across the entire age range. It also shows that noise decreases with age for the pragmatics model, suggesting that older children behaved more in line with model predictions compared to younger children. 

```{r childnoise, include = T, fig.cap = "Posterior distribution of noise parameter for each model in Experiment 7. A: single noise parameter across age, B: Developmental noise parameter.", fig.height = 2.5}
ggarrange(child_noise_plot,child_dev_noise_plot, nrow = 1, ncol = 2, common.legend = T, legend = "right", labels = c("A","B"))
```




\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup


