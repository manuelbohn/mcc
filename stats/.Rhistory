ggplot(child_model_predictions)+
#geom_jitter(data = plot_child_ex3_data, aes(x = age_num, y = mean), width = .025,height = .025, alpha = .2)+
geom_line(aes(x = age, y = value, col = model), size = 1, alpha = 1, linetype = 1) +
geom_smooth(data = child_ex3_data, aes(x = age_num, y = correct_inf), col = "black", size = 0.6, method = "loess", span = 1.5,  se = T,  alpha = .5)+
#geom_hline(yintercept = 0.5, lty=2)+
labs(y="proportion more informative")+
ylim(-0.05,1.05)+
facet_grid(speaker~alignment)+
theme_few()+
scale_color_manual(name="Model",
breaks=c("pragmatic","flat_prior","prior_only"),
values= c("#859900","#6c71c4","#b58900"))+
scale_fill_manual(name="Model",
breaks=c("pragmatic","flat_prior","prior_only"),
values= c("#859900","#6c71c4","#b58900"))
child_cor_data <- child_ex3_data %>%
filter(trial != "filler1",
trial != "filler2")%>%
group_by(speaker, alignment, age_bin) %>%
summarize(k = sum(correct_inf), n = n())%>%
ungroup() %>%
mutate(a = 1 + k,
b = 1 + n - k,
Data_ci_lower  = qbeta(.025, a, b),
Data_ci_upper = qbeta(.975, a, b),
Data = (a-1)/(a+b-2))%>%
select(-a,-b,-n,-k)
child_cor_model <- child_model_predictions %>%
mutate(age = ifelse(age<4,"3","4"))%>%
group_by(model,speaker,alignment, age)%>%
summarise(Model = mean(value))
child_cor_plot <- child_cor_model %>%
ungroup()%>%
mutate(Data = rep(child_cor_data$Data,3),
Data_ci_lower = rep(child_cor_data$Data_ci_lower,3),
Data_ci_upper  =rep( child_cor_data$Data_ci_upper,3))
ggplot(data = child_cor_plot,aes(x = Model, y = Data, col = age)) +
geom_abline(intercept = 0, slope = 1, lty = 2, alpha = 1, size = .5)+
geom_point(size = 3)+
geom_errorbar(aes(ymin = Data_ci_lower, ymax = Data_ci_upper),width = 0,size = .5)+
coord_fixed()+
facet_grid(~model)+
stat_cor(method = "pearson", label.x = 0.01, label.y = 0.99, aes(x = Model, y = Data), inherit.aes = F)+
xlim(0,1)+ylim(0,1)+
xlab("Model")+
theme_few() +
scale_colour_ptol()
# calculating model log-likelihoods
log_like_pragmatic <- child_ex3_pragm_model_predictions %>%
mutate(like = ifelse(correct == "1",value,1-value),
log_like = log(like))%>%
group_by(model)%>%
summarise(model_log_like = sum(log_like))
log_like_flat_prior <- child_ex3_flat_prior_model_predictions %>%
mutate(like = ifelse(correct == "1",value,1-value),
log_like = log(like))%>%
group_by(model)%>%
summarise(model_log_like = sum(log_like))
log_like_prior_only <- child_ex3_prior_only_model_predictions %>%
mutate(like = ifelse(correct == "1",value,1-value),
log_like = log(like))%>%
group_by(model)%>%
summarise(model_log_like = sum(log_like))
child_ex3_model_comparison <- bind_rows(
log_like_pragmatic,
log_like_flat_prior,
log_like_prior_only
)%>%
mutate(model = reorder(model,model_log_like))
ggplot(child_ex3_model_comparison, aes(x = model, y = model_log_like, col = model))+
geom_segment( aes(x=model, xend=model, y=-425, yend=model_log_like), col = "black", size = 1)+
geom_point(size = 7)+
theme_few()+
xlab("Model")+
ylab("Log-likelihood")+
theme(axis.text.x=element_text(angle = 45, vjust = 1, hjust = 1))+
guides(col = F)+
ylim(-550,-425)+
scale_color_manual(breaks=c("pragmatic","prior_only","flat_prior"),
values= c("#b58900","#859900","#6c71c4"))
child_ex3_bf <- data.frame(
comparison = c("pragmatic vs. flat_prior","pragmatic vs. prior_only", "flat_rior vs. prior_only"),
log_bayes_factor = c(
log_like_pragmatic$model_log_like - log_like_flat_prior$model_log_like,
log_like_pragmatic$model_log_like- log_like_prior_only$model_log_like,
log_like_flat_prior$model_log_like - log_like_prior_only$model_log_like)
)
child_ex3_bf%>%
kable(digits = 2)
exp(5.58)
exp(4.58)
ggplot(child_model_predictions)+
#geom_jitter(data = plot_child_ex3_data, aes(x = age_num, y = mean), width = .025,height = .025, alpha = .2)+
geom_line(aes(x = age, y = value, col = model), size = 1, alpha = 1, linetype = 1) +
geom_smooth(data = child_ex3_data, aes(x = age_num, y = correct_inf), col = "black", size = 0.6, method = "loess", span = 1,  se = T,  alpha = .5)+
#geom_hline(yintercept = 0.5, lty=2)+
labs(y="proportion more informative")+
ylim(-0.05,1.05)+
facet_grid(speaker~alignment)+
theme_few()+
scale_color_manual(name="Model",
breaks=c("pragmatic","flat_prior","prior_only"),
values= c("#859900","#6c71c4","#b58900"))+
scale_fill_manual(name="Model",
breaks=c("pragmatic","flat_prior","prior_only"),
values= c("#859900","#6c71c4","#b58900"))
ggplot(child_model_predictions)+
#geom_jitter(data = plot_child_ex3_data, aes(x = age_num, y = mean), width = .025,height = .025, alpha = .2)+
geom_line(aes(x = age, y = value, col = model), size = 1, alpha = 1, linetype = 1) +
geom_smooth(data = child_ex3_data, aes(x = age_num, y = correct_inf), col = "black", size = 0.6, method = "loess", span = 1.1,  se = T,  alpha = .5)+
#geom_hline(yintercept = 0.5, lty=2)+
labs(y="proportion more informative")+
ylim(-0.05,1.05)+
facet_grid(speaker~alignment)+
theme_few()+
scale_color_manual(name="Model",
breaks=c("pragmatic","flat_prior","prior_only"),
values= c("#859900","#6c71c4","#b58900"))+
scale_fill_manual(name="Model",
breaks=c("pragmatic","flat_prior","prior_only"),
values= c("#859900","#6c71c4","#b58900"))
ggplot(child_model_predictions)+
#geom_jitter(data = plot_child_ex3_data, aes(x = age_num, y = mean), width = .025,height = .025, alpha = .2)+
geom_line(aes(x = age, y = value, col = model), size = 1, alpha = 1, linetype = 1) +
geom_smooth(data = child_ex3_data, aes(x = age_num, y = correct_inf), col = "black", size = 0.6, method = "loess", span = 2,  se = T,  alpha = .5)+
#geom_hline(yintercept = 0.5, lty=2)+
labs(y="proportion more informative")+
ylim(-0.05,1.05)+
facet_grid(speaker~alignment)+
theme_few()+
scale_color_manual(name="Model",
breaks=c("pragmatic","flat_prior","prior_only"),
values= c("#859900","#6c71c4","#b58900"))+
scale_fill_manual(name="Model",
breaks=c("pragmatic","flat_prior","prior_only"),
values= c("#859900","#6c71c4","#b58900"))
child_model_param
childModelParam <- '
var prefData = dataFromR.prefData
var infData = dataFromR.infData
var all_conditions = levels(prefData, "condition")
var model  = function(){
var so_slope = uniformDrift({a: -2, b: 2, width: 0.2})
var so_int = uniformDrift({a: -2, b: 2, width: 0.2})
foreach(function(row){
var age = row.age_num
var speakerOptimality = so_int  + so_slope * (age - infData[0].minage)
var inf_priorProbs = [.5, .5, .5]
var rsaPredictions = pragmaticListener({label: "dax", point: 2 },
inf_priorProbs, speakerOptimality)
observe(rsaPredictions, row.correct)
}, infData)
var pref_params = map(function(cndtn){
var conditionData = _.filter(prefData, {condition: cndtn})
var pref_slope = uniformDrift({a: -2, b: 2, width: 0.4})
var pref_int = uniformDrift({a: -2, b: 2, width: 0.4})
foreach(function(row){
var age = row.age_num
var priorReg = logistic(pref_int + pref_slope * (age - row.minage))
var priorProbs= [1-priorReg, priorReg]
var priorPredictions = Infer({method: "enumerate", model: function(){
var obj = sample( Categorical({vs: prior_objects, ps: priorProbs}));
return obj.shape == "circle" ? 1 : 0
}})
observe(priorPredictions, row.correct)
}, conditionData)
return [
{param: "pref_int", val: pref_int, condition: cndtn},
{param: "pref_slope", val: pref_slope, condition: cndtn}
]
}, all_conditions)
return _.flatten(pref_params).concat(
[
{ param: "so_slope", val: so_slope},
{ param: "so_int", val: so_int}
]
)
}
'
child_model_param<- webppl(
program_code = paste(rsaUtils, rsaModel, childModelParam , sep='\n'),
data = list(prefData = child_ex2_data, infData = child_ex1_data),
data_var = "dataFromR",
model_var = "model",
chains = 4,
cores = 4,
inference_opts = list(method = "MCMC", samples = 6000, burn = 2000, verbose = T)
)%>%
saveRDS("../../stats/saves/child_model_param.rds")
child_model_param <- readRDS("../../stats/saves/child_model_param.rds")%>%
select(value) %>%
map_df(bind_rows)%>%
group_by(param,condition)%>%
summarise(param_map = estimate_mode(val))%>%
mutate(cond = paste(param,condition, sep = "_"))%>%
ungroup()%>%
select(cond,param_map)%>%
spread(cond,param_map)%>%
rename(so_int = so_int_NA,
so_slope = so_slope_NA)
child_model_param
# visualize inferred parameter
plot_child_model_param <- readRDS("../../stats/saves/child_model_param.rds")%>%
select(value)%>%
map_df(bind_rows)%>%
mutate(type = ifelse(grepl("pref",param),"prior", "speaker optimality"))
ggplot(plot_child_model_param, aes(val))+
geom_density()+
xlab("Parameter")+
facet_grid(type~param+condition)+
theme_few()
# visualize model priors in comparison to data
child_prior_plot <- child_ex2_data %>%
group_by(id,age_num,minage,condition)%>%
summarise(correct = mean(correct))%>%
mutate(model = ifelse(condition == "different_speaker",
plogis(child_model_param$pref_int_different_speaker + child_model_param$pref_slope_different_speaker * (age_num-minage)),
plogis(child_model_param$pref_int_same_speaker + child_model_param$pref_slope_same_speaker * (age_num-minage)
)))
ggplot(data = child_prior_plot, aes(x = age_num, y = correct, col = condition)) +
geom_jitter(alpha = 0.5, height = 0.02, width = 0)+
geom_smooth(aes(fill = condition),method = "lm", se = T, alpha = .5, size = .7)+
geom_line(aes(x = age_num, y = model, col = condition), size = 1.5, lty = 2)+
geom_hline(yintercept = 0.5, lty=2)+
labs(x="Age",y="Proportion Correct")+
theme_few() +
ylim(-0.05,1.05)+
guides(alpha = F)+
scale_color_solarized(name = "Condition")+
scale_fill_solarized(name = "Condition")
# visualize speaker optimality in comparison to data
child_so_plot <- child_ex1_data %>%
group_by(id,age_num,minage)%>%
summarise(correct = mean(correct))%>%
mutate(model = child_model_param$so_int + child_model_param$so_slope * (age_num - minage))
ggplot(data = child_so_plot, aes(x = age_num, y = model)) +
geom_line(alpha = .5, size = .7)+
labs(x="Age",y="Speaker optimality parameter")+
theme_few() +
geom_hline(yintercept = 0, lty=2)+
ylim(-3,3)+
guides(alpha = F)
ex3_model_data <- child_ex3_data%>%
mutate(so_int = child_model_param$so_int,
so_slope = child_model_param$so_slope,
pref_int_different_speaker = child_model_param$pref_int_different_speaker,
pref_slope_different_speaker = child_model_param$pref_slope_different_speaker,
pref_int_same_speaker = child_model_param$pref_int_same_speaker,
pref_slope_same_speaker = child_model_param$pref_slope_same_speaker,
so = so_int+so_slope*(age_num-min(age_num)),
diff_prior = plogis(pref_int_different_speaker+pref_slope_different_speaker*(age_num-min(age_num))),
same_prior = plogis(pref_int_same_speaker+pref_slope_same_speaker*(age_num-min(age_num))))%>%
group_by(id,trial)%>%
mutate(priorProbs = ifelse(speaker == "same_speaker" & alignment == "congruent", list(c(1-same_prior,1-same_prior,same_prior)),
ifelse(speaker == "different_speaker" & alignment == "congruent", list(c(1-diff_prior,1-diff_prior,diff_prior)),
ifelse(speaker == "same_speaker" & alignment == "incongruent", list(c(same_prior,same_prior,1-same_prior)),
list(c(diff_prior,diff_prior,1-diff_prior))
))))%>%
ungroup()%>%
select(speaker,age_num,minage,alignment,so,priorProbs,correct_inf)
child.ex3.rsa.predictions <-'
var allData = dataFromR.ex3data
var output = map(function(row){
var modelPredictions = pragmaticListener({label: "dax", point: 2 }, row.priorProbs,row.so)
return extend([row.age_num + "/" + row.speaker + "/" + row.alignment + "/" + row.correct_inf, Math.exp(modelPredictions.score(1))])
}, allData)
output
'
child_ex3_pragm_model<- webppl(
program_code = paste(rsaUtils, rsaModel, child.ex3.rsa.predictions , sep='\n'),
data =list(ex3data = ex3_model_data),
data_var = "dataFromR"
)
# model predictions
child_ex3_pragm_model_predictions <- child_ex3_pragm_model %>%
separate(`0`, into = c("age", "speaker", "alignment","correct"), sep="/")%>%
mutate(value = `1`,
model="pragmatic",
age = as.numeric(age))%>%
select(-`1`)
child.ex3.prior.only.predictions <-'
var allData = dataFromR.ex3data
var output = map(function(row){
var modelPredictions = Infer({method: "enumerate", model: function(){
var obj = sample( Categorical({vs: all_objects, ps: row.priorProbs}));
return obj.shape == "circle" ? 1 : 0
}})
return  extend([row.age_num + "/" + row.speaker + "/" + row.alignment+ "/" + row.correct_inf, Math.exp(modelPredictions.score(1))])
}, allData)
output
'
child_ex3_prior_only_model<- webppl(
program_code = paste(rsaUtils, rsaModel, child.ex3.prior.only.predictions , sep='\n'),
data =list(ex3data = ex3_model_data),
data_var = "dataFromR"
)
# model predictions
child_ex3_prior_only_model_predictions <- child_ex3_prior_only_model %>%
separate(`0`, into = c("age", "speaker", "alignment","correct"), sep="/")%>%
mutate(value = `1`,
model="prior_only",
age = as.numeric(age))%>%
select(-`1`)
child.ex3.flat.prior.predictions <-'
var allData = dataFromR.ex3data
var output = map(function(row){
var prior = [.5, .5, .5]
var modelPredictions = pragmaticListener({label: "dax", point: 2 }, prior,row.so)
return  extend([row.age_num + "/" + row.speaker + "/" + row.alignment + "/" + row.correct_inf, Math.exp(modelPredictions.score(1))])
}, allData)
output
'
child_ex3_flat_prior_model<- webppl(
program_code = paste(rsaUtils, rsaModel, child.ex3.flat.prior.predictions , sep='\n'),
data =list(ex3data = ex3_model_data),
data_var = "dataFromR")
# model predictions
child_ex3_flat_prior_model_predictions <- child_ex3_flat_prior_model %>%
separate(`0`, into = c("age", "speaker", "alignment","correct"), sep="/")%>%
mutate(value = `1`,
model="flat_prior",
age = as.numeric(age))%>%
select(-`1`)
child_model_predictions <- bind_rows(
child_ex3_pragm_model_predictions,
child_ex3_flat_prior_model_predictions,
child_ex3_prior_only_model_predictions
)
plot_child_ex3_data <- child_ex3_data%>%
group_by(age_num,speaker,alignment)%>%
summarise(mean = mean(correct_inf))
ggplot(child_model_predictions)+
#geom_jitter(data = plot_child_ex3_data, aes(x = age_num, y = mean), width = .025,height = .025, alpha = .2)+
geom_line(aes(x = age, y = value, col = model), size = 1, alpha = 1, linetype = 1) +
geom_smooth(data = child_ex3_data, aes(x = age_num, y = correct_inf), col = "black", size = 0.6, method = "loess", span = 2,  se = T,  alpha = .5)+
#geom_hline(yintercept = 0.5, lty=2)+
labs(y="proportion more informative")+
ylim(-0.05,1.05)+
facet_grid(speaker~alignment)+
theme_few()+
scale_color_manual(name="Model",
breaks=c("pragmatic","flat_prior","prior_only"),
values= c("#859900","#6c71c4","#b58900"))+
scale_fill_manual(name="Model",
breaks=c("pragmatic","flat_prior","prior_only"),
values= c("#859900","#6c71c4","#b58900"))
child_cor_data <- child_ex3_data %>%
filter(trial != "filler1",
trial != "filler2")%>%
group_by(speaker, alignment, age_bin) %>%
summarize(k = sum(correct_inf), n = n())%>%
ungroup() %>%
mutate(a = 1 + k,
b = 1 + n - k,
Data_ci_lower  = qbeta(.025, a, b),
Data_ci_upper = qbeta(.975, a, b),
Data = (a-1)/(a+b-2))%>%
select(-a,-b,-n,-k)
child_cor_model <- child_model_predictions %>%
mutate(age = ifelse(age<4,"3","4"))%>%
group_by(model,speaker,alignment, age)%>%
summarise(Model = mean(value))
child_cor_plot <- child_cor_model %>%
ungroup()%>%
mutate(Data = rep(child_cor_data$Data,3),
Data_ci_lower = rep(child_cor_data$Data_ci_lower,3),
Data_ci_upper  =rep( child_cor_data$Data_ci_upper,3))
ggplot(data = child_cor_plot,aes(x = Model, y = Data, col = age)) +
geom_abline(intercept = 0, slope = 1, lty = 2, alpha = 1, size = .5)+
geom_point(size = 3)+
geom_errorbar(aes(ymin = Data_ci_lower, ymax = Data_ci_upper),width = 0,size = .5)+
coord_fixed()+
facet_grid(~model)+
stat_cor(method = "pearson", label.x = 0.01, label.y = 0.99, aes(x = Model, y = Data), inherit.aes = F)+
xlim(0,1)+ylim(0,1)+
xlab("Model")+
theme_few() +
scale_colour_ptol()
# calculating model log-likelihoods
log_like_pragmatic <- child_ex3_pragm_model_predictions %>%
mutate(like = ifelse(correct == "1",value,1-value),
log_like = log(like))%>%
group_by(model)%>%
summarise(model_log_like = sum(log_like))
log_like_flat_prior <- child_ex3_flat_prior_model_predictions %>%
mutate(like = ifelse(correct == "1",value,1-value),
log_like = log(like))%>%
group_by(model)%>%
summarise(model_log_like = sum(log_like))
log_like_prior_only <- child_ex3_prior_only_model_predictions %>%
mutate(like = ifelse(correct == "1",value,1-value),
log_like = log(like))%>%
group_by(model)%>%
summarise(model_log_like = sum(log_like))
child_ex3_model_comparison <- bind_rows(
log_like_pragmatic,
log_like_flat_prior,
log_like_prior_only
)%>%
mutate(model = reorder(model,model_log_like))
ggplot(child_ex3_model_comparison, aes(x = model, y = model_log_like, col = model))+
geom_segment( aes(x=model, xend=model, y=-425, yend=model_log_like), col = "black", size = 1)+
geom_point(size = 7)+
theme_few()+
xlab("Model")+
ylab("Log-likelihood")+
theme(axis.text.x=element_text(angle = 45, vjust = 1, hjust = 1))+
guides(col = F)+
ylim(-550,-425)+
scale_color_manual(breaks=c("pragmatic","prior_only","flat_prior"),
values= c("#b58900","#859900","#6c71c4"))
child_ex3_bf <- data.frame(
comparison = c("pragmatic vs. flat_prior","pragmatic vs. prior_only", "flat_rior vs. prior_only"),
log_bayes_factor = c(
log_like_pragmatic$model_log_like - log_like_flat_prior$model_log_like,
log_like_pragmatic$model_log_like- log_like_prior_only$model_log_like,
log_like_flat_prior$model_log_like - log_like_prior_only$model_log_like)
)
child_ex3_bf%>%
kable(digits = 2)
exp(2.58)
speakOptParam <- '
var data = dataFromR.data
var model  = function(){
var speakerOptimality = uniformDrift({a: -4, b: 4, width: 0.5})
foreach(function(row){
var priorProbs = [.5, .5, .5]
var rsaPredictions = pragmaticListener({label: "dax", point: 2 },
priorProbs, speakerOptimality)
observe(rsaPredictions, row.correct)
}, data)
return speakerOptimality
}
'
adult_model_param<- webppl(
program_code = paste(rsaUtils, rsaModel, speakOptParam , sep='\n'),
data = list(data = adult_ex1_data),
data_var = "dataFromR",
model_var = "model",
chains = 4,
cores = 4,
inference_opts = list(method = "MCMC", samples = 6000, burn = 2000, verbose = T)
)%>%
saveRDS("../../stats/saves/adult_model_param.rds")
adult_model_param <- readRDS("../../stats/saves/adult_model_param.rds")%>%
select(value) %>%
summarise(so_map = estimate_mode(value),
ci_lower = hdi_lower(value),
ci_upper = hdi_upper(value))
adult_model_param
# visualize speaker optimality parameter
plot_adult_model_speak_opt <- readRDS("../../stats/saves/adult_model_param.rds")%>%
select(value)
ggplot(plot_adult_model_speak_opt, aes(value))+
geom_density()+
xlab("Speaker optimality")+
theme_few()
model_params_ex3
adult_model_param
childModelParam <- '
var prefData = dataFromR.prefData
var infData = dataFromR.infData
var all_conditions = levels(prefData, "condition")
var model  = function(){
var so_slope = uniformDrift({a: -4, b: 4, width: 0.2})
var so_int = uniformDrift({a: -4, b: 4, width: 0.2})
foreach(function(row){
var age = row.age_num
var speakerOptimality = so_int  + so_slope * (age - infData[0].minage)
var inf_priorProbs = [.5, .5, .5]
var rsaPredictions = pragmaticListener({label: "dax", point: 2 },
inf_priorProbs, speakerOptimality)
observe(rsaPredictions, row.correct)
}, infData)
var pref_params = map(function(cndtn){
var conditionData = _.filter(prefData, {condition: cndtn})
var pref_slope = uniformDrift({a: -2, b: 2, width: 0.4})
var pref_int = uniformDrift({a: -2, b: 2, width: 0.4})
foreach(function(row){
var age = row.age_num
var priorReg = logistic(pref_int + pref_slope * (age - row.minage))
var priorProbs= [1-priorReg, priorReg]
var priorPredictions = Infer({method: "enumerate", model: function(){
var obj = sample( Categorical({vs: prior_objects, ps: priorProbs}));
return obj.shape == "circle" ? 1 : 0
}})
observe(priorPredictions, row.correct)
}, conditionData)
return [
{param: "pref_int", val: pref_int, condition: cndtn},
{param: "pref_slope", val: pref_slope, condition: cndtn}
]
}, all_conditions)
return _.flatten(pref_params).concat(
[
{ param: "so_slope", val: so_slope},
{ param: "so_int", val: so_int}
]
)
}
'
child_model_param<- webppl(
program_code = paste(rsaUtils, rsaModel, childModelParam , sep='\n'),
data = list(prefData = child_ex2_data, infData = child_ex1_data),
data_var = "dataFromR",
model_var = "model",
chains = 4,
cores = 4,
inference_opts = list(method = "MCMC", samples = 8000, burn = 2000, verbose = T)
)%>%
saveRDS("../../stats/saves/child_model_param.rds")
kill_webppl()
