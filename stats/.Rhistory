load("model.comparisons.RData")
llh.rsa
prior.loglikelihood <-'
var allConditions = dataFromR.allConditions
var allData = dataFromR.allData
var allPriorProbs = dataFromR.allPriorProbs
var model = function(){
var conditionOutput = map(function(conditionInfo){
var conditionSpecificData =  _.filter(allData,
{Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
var conditionSpecificPriors =  _.filter(allPriorProbs,
{Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
var priorOnlyPredictions = Infer({method: "enumerate", model: function(){
var obj = sample( Categorical({vs: all_objects, ps: conditionSpecificPriors[0].priorProbs}));
return obj.shape == "circle" ? 1 : 0
}})
var loglike = sum(map(function(d){
return priorOnlyPredictions.score(d.correct_inf)
}, conditionSpecificData))
return  loglike
}, allConditions)
return sum(conditionOutput)
}
'
rsa.loglikelihood <-'
var allConditions = dataFromR.allConditions
var allData = dataFromR.allData
var allPriorProbs = dataFromR.allPriorProbs
var model = function(){
var conditionOutput = map(function(conditionInfo){
var conditionSpecificData =  _.filter(allData, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
var conditionSpecificPriors =  _.filter(allPriorProbs, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
var modelPredictions = pragmaticListener({label: "dax", point: 2 }, conditionSpecificPriors[0].priorProbs)
var loglike = sum(map(function(d){
return modelPredictions.score(d.correct_inf)
}, conditionSpecificData))
return  loglike
}, allConditions)
return sum(conditionOutput)
}
'
rsa.noise.loglikelihood <-'
var allConditions = dataFromR.allConditions
var allData = dataFromR.allData
var allPriorProbs = dataFromR.allPriorProbs
var model = function(){
var noise = uniformDrift({a: 0, b:1, width: 0.1})
var conditionOutput = map(function(conditionInfo){
var conditionSpecificData =  _.filter(allData, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
var conditionSpecificPriors =  _.filter(allPriorProbs, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
//display(JSON.stringify(conditionSpecificData[0].correct_inf))
var modelPredictions = pragmaticListener({label: "dax", point: 2 }, conditionSpecificPriors[0].priorProbs)
var noisyModelPredictions = addNoise(modelPredictions, noise)
var loglike = sum(map(function(d){
return noisyModelPredictions.score(d.correct_inf)
}, conditionSpecificData))
return  loglike
}, allConditions)
return sum(conditionOutput)
}
'
prior.noise.loglikelihood <-'
var allConditions = dataFromR.allConditions
var allData = dataFromR.allData
var allPriorProbs = dataFromR.allPriorProbs
var model = function(){
var noise = uniformDrift({a: 0, b:1, width: 0.1})
var conditionOutput = map(function(conditionInfo){
var conditionSpecificData =  _.filter(allData,
{Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
var conditionSpecificPriors =  _.filter(allPriorProbs,
{Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
var priorOnlyPredictions = Infer({method: "enumerate", model: function(){
var obj = sample( Categorical({vs: all_objects, ps: conditionSpecificPriors[0].priorProbs}));
return obj.shape == "circle" ? 1 : 0
}})
var noisyModelPredictions = addNoise(priorOnlyPredictions, noise)
var loglike = sum(map(function(d){
return noisyModelPredictions.score(d.correct_inf)
}, conditionSpecificData))
return  loglike
}, allConditions)
return sum(conditionOutput)
}
'
rsa.regPrior.loglikelihood <-'
var allConditions = dataFromR.allConditions
var allData = dataFromR.allData
var allPriorProbs = dataFromR.allPriorProbs
var model = function(){
var priorExponent = uniformDrift({a: 0, b:5, width: 0.1})
var conditionOutput = map(function(conditionInfo){
var conditionSpecificData =  _.filter(allData, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
var conditionSpecificPriors =  _.filter(allPriorProbs, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
var regularizedPriors = normalize(map(function(i){ return Math.pow(i, priorExponent) },
conditionSpecificPriors[0].priorProbs))
var modelPredictions = pragmaticListener({label: "dax", point: 2 }, regularizedPriors)
var loglike = sum(map(function(d){
return modelPredictions.score(d.correct_inf)
}, conditionSpecificData))
return  loglike
}, allConditions)
return sum(conditionOutput)
}
'
prior.regPrior.loglikelihood <-'
var allConditions = dataFromR.allConditions
var allData = dataFromR.allData
var allPriorProbs = dataFromR.allPriorProbs
var model = function(){
var priorExponent = uniformDrift({a: 0, b:5, width: 0.1})
var conditionOutput = map(function(conditionInfo){
var conditionSpecificData =  _.filter(allData, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
var conditionSpecificPriors =  _.filter(allPriorProbs, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
var regularizedPriors = normalize(map(function(i){ return Math.pow(i, priorExponent) },
conditionSpecificPriors[0].priorProbs))
var modelPredictions = Infer({method: "enumerate", model: function(){
var obj = sample( Categorical({vs: all_objects, ps: regularizedPriors}));
return obj.shape == "circle" ? 1 : 0
}})
var loglike = sum(map(function(d){
return modelPredictions.score(d.correct_inf)
}, conditionSpecificData))
return  loglike
}, allConditions)
return sum(conditionOutput)
}
'
rsa.regularizedPrior.noise.loglikelihood <-'
var allConditions = dataFromR.allConditions
var allData = dataFromR.allData
var allPriorProbs = dataFromR.allPriorProbs
var model = function(){
var priorExponent = uniformDrift({a: 0, b:5, width: 0.1})
var noise = uniformDrift({a: 0, b:1, width: 0.1})
var conditionOutput = map(function(conditionInfo){
var conditionSpecificData =  _.filter(allData, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
var conditionSpecificPriors =  _.filter(allPriorProbs, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
var regularizedPriors = normalize(map(function(i){ return Math.pow(i, priorExponent) },
conditionSpecificPriors[0].priorProbs))
var modelPredictions = pragmaticListener({label: "dax", point: 2 }, regularizedPriors)
var noisyModelPredictions = addNoise(modelPredictions, noise)
var loglike = sum(map(function(d){
return noisyModelPredictions.score(d.correct_inf)
}, conditionSpecificData))
return  loglike
}, allConditions)
return sum(conditionOutput)
}
'
prior.regularizedPrior.noise.likelihood <-'
var allConditions = dataFromR.allConditions
var allData = dataFromR.allData
var allPriorProbs = dataFromR.allPriorProbs
var model = function(){
var priorExponent = uniformDrift({a: 0, b:5, width: 0.1})
var noise = uniformDrift({a: 0, b:1, width: 0.1})
var conditionOutput = map(function(conditionInfo){
var conditionSpecificData =  _.filter(allData, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
var conditionSpecificPriors =  _.filter(allPriorProbs, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})
var regularizedPriors = normalize(map(function(i){ return Math.pow(i, priorExponent) },
conditionSpecificPriors[0].priorProbs))
var modelPredictions = Infer({method: "enumerate", model: function(){
var obj = sample( Categorical({vs: all_objects, ps: regularizedPriors}));
return obj.shape == "circle" ? 1 : 0
}})
var noisyModelPredictions = addNoise(modelPredictions, noise)
var loglike = sum(map(function(d){
return noisyModelPredictions.score(d.correct_inf)
}, conditionSpecificData))
return  loglike
}, allConditions)
return sum(conditionOutput)
}
'
llh.prior.noise.regPrior
llh.rsa.noise.regPrior
llh.rsa.regPrior
llh.prior.regPrior
llh.rsa.noise
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(ggthemes)
library(langcog)
library(rwebppl)
no_prior
predictions
no_prior <- predictions %>%
filter(Model == "No prior")%>%
mutate(condition = con)
con <- c("pref_inf_same_congruent",
"pref_inf_same_incongruent",
"pref_inf_diff_congruent",
"pref_inf_diff_incongruent",
"novel_inf_same_congruent",
"novel_inf_same_incongruent",
"novel_inf_diff_congruent",
"novel_inf_diff_incongruent")
no_prior <- predictions %>%
filter(Model == "No prior")%>%
mutate(condition = con)
model_comparison <- rbind(
# left_join(
#  wp.rs.all %>% filter(obj == "circle")%>%mutate(exp = substr(condition,1,4)) %>%select(condition,exp,Model,prob),
# data.summary),
left_join(
no_prior%>%mutate(prob = corr, exp = substr(condition,1,4))%>%select(condition,exp,Model,prob),
data.summary),
left_join(
prior_only%>%mutate(prob = corr, exp = substr(condition,1,4))%>%select(condition,exp,Model,prob),
data.summary)
)
data.summary <- data %>%
mutate(condition = paste(experiment,change, alignment, sep = "_")) %>%
group_by(condition) %>%
summarize(n= n(),
k = sum(correct_inf))
model_comparison <- rbind(
# left_join(
#  wp.rs.all %>% filter(obj == "circle")%>%mutate(exp = substr(condition,1,4)) %>%select(condition,exp,Model,prob),
# data.summary),
left_join(
no_prior%>%mutate(prob = corr, exp = substr(condition,1,4))%>%select(condition,exp,Model,prob),
data.summary),
left_join(
prior_only%>%mutate(prob = corr, exp = substr(condition,1,4))%>%select(condition,exp,Model,prob),
data.summary)
)
prior_only <- predictions %>%
filter(Model == "Prior only")%>%
mutate(condition = con)
model_comparison <- rbind(
# left_join(
#  wp.rs.all %>% filter(obj == "circle")%>%mutate(exp = substr(condition,1,4)) %>%select(condition,exp,Model,prob),
# data.summary),
left_join(
no_prior%>%mutate(prob = corr, exp = substr(condition,1,4))%>%select(condition,exp,Model,prob),
data.summary),
left_join(
prior_only%>%mutate(prob = corr, exp = substr(condition,1,4))%>%select(condition,exp,Model,prob),
data.summary)
)
comp_model<- model_comparison%>%
mutate(p_data_given_model = dbinom(size = n, p = prob, x = k, log = T)) %>%
group_by(Model) %>%
summarize(log_p_data_given_model = sum(p_data_given_model))
comp_model
llh.prior.regPrior <- webppl(
program_code = paste(rsaUtils, rsaModel2, prior.regPrior.loglikelihood, sep='\n'),
data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs),
data_var = "dataFromR",
model_var = "model",
inference_opts = list(method = "forward", samples = 1e+5, chains = 3, cores = 3)
)%>%
mutate(Model = "Prior only Regularized")
save.image(file="model.comparisons.RData")
likelihood_overview <- bind_rows(
# llh.rsa,
# llh.prior,
# llh.rsa.noise,
llh.prior.regPrior,
llh.rsa.regPrior,
llh.rsa.noise.regPrior,
llh.prior.noise.regPrior)
ggplot(likelihood_overview, aes(x = value))+
geom_histogram()+
xlim(-700,-500)+
facet_wrap(~Model)
llh.plot <- likelihood_overview %>%
group_by(Model)%>%
summarize(logSumExp = logSumExp(value))%>%
mutate(Model = reorder(Model,logSumExp))
library(matrixStats)
llh.plot <- likelihood_overview %>%
group_by(Model)%>%
summarize(logSumExp = logSumExp(value))%>%
mutate(Model = reorder(Model,logSumExp))
ggplot(llh.plot, aes(x = Model, y = logSumExp, fill = Model))+
geom_bar(stat="identity", color = "black")+
ggtitle("logsumexp per model")+
theme_few()+
theme(axis.text.x=element_text(angle = 45, vjust = 1, hjust = 1))
llh.rsa.noise <- webppl(
program_code = paste(rsaUtils, rsaModel2, rsa.noise.loglikelihood, sep='\n'),
data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs),
data_var = "dataFromR",
model_var = "model",
inference_opts = list(method = "forward", samples = 1e+5, chains = 3, cores = 3)
)%>%
mutate(Model = "RSA Noisy")
llh.rsa <- webppl(
program_code = paste(rsaUtils, rsaModel2, rsa.loglikelihood, sep='\n'),
data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs),
data_var = "dataFromR",
model_var = "model",
inference_opts = list(method = "forward", samples = 100, chains = 3, cores = 3)
)%>%
mutate(Model = "RSA")
llh.prior <- webppl(
program_code = paste(rsaUtils, rsaModel2, prior.loglikelihood, sep='\n'),
data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs),
data_var = "dataFromR",
model_var = "model",
inference_opts = list(method = "forward", samples = 100, chains = 3, cores = 3)
)%>%
mutate(Model = "Prior only")
likelihood_overview <- bind_rows(
llh.rsa,
llh.prior,
llh.rsa.noise,
llh.prior.regPrior,
llh.rsa.regPrior,
llh.rsa.noise.regPrior,
llh.prior.noise.regPrior)
ggplot(likelihood_overview, aes(x = value))+
geom_histogram()+
xlim(-700,-500)+
facet_wrap(~Model)
ggplot(likelihood_overview, aes(x = value))+
geom_histogram()+
xlim(-900,-500)+
facet_wrap(~Model)
ggplot(likelihood_overview, aes(x = value))+
geom_histogram()+
xlim(-700,-500)+
facet_wrap(~Model)
llh.plot <- likelihood_overview %>%
group_by(Model)%>%
summarize(logSumExp = logSumExp(value))%>%
mutate(Model = reorder(Model,logSumExp))
ggplot(llh.plot, aes(x = Model, y = logSumExp, fill = Model))+
geom_bar(stat="identity", color = "black")+
ggtitle("logsumexp per model")+
theme_few()+
theme(axis.text.x=element_text(angle = 45, vjust = 1, hjust = 1))
llh.rsa <- webppl(
program_code = paste(rsaUtils, rsaModel2, rsa.loglikelihood, sep='\n'),
data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs),
data_var = "dataFromR",
model_var = "model",
inference_opts = list(method = "forward", samples = 5000, chains = 3, cores = 3)
)%>%
mutate(Model = "RSA")
llh.prior <- webppl(
program_code = paste(rsaUtils, rsaModel2, prior.loglikelihood, sep='\n'),
data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs),
data_var = "dataFromR",
model_var = "model",
inference_opts = list(method = "forward", samples = 5000, chains = 3, cores = 3)
)%>%
mutate(Model = "Prior only")
likelihood_overview <- bind_rows(
llh.rsa,
llh.prior,
llh.rsa.noise,
llh.prior.regPrior,
llh.rsa.regPrior,
llh.rsa.noise.regPrior,
llh.prior.noise.regPrior)
ggplot(likelihood_overview, aes(x = value))+
geom_histogram()+
xlim(-700,-500)+
facet_wrap(~Model)
llh.plot <- likelihood_overview %>%
group_by(Model)%>%
summarize(logSumExp = logSumExp(value))%>%
mutate(Model = reorder(Model,logSumExp))
ggplot(llh.plot, aes(x = Model, y = logSumExp, fill = Model))+
geom_bar(stat="identity", color = "black")+
ggtitle("logsumexp per model")+
theme_few()+
theme(axis.text.x=element_text(angle = 45, vjust = 1, hjust = 1))
save.image(file="model.comparisons.RData")
bda <- webppl(
program_code = paste(rsaUtils, rsaModel2, bdaModel.rsa.noise, sep='\n'),
data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs),
data_var = "dataFromR",
model_var = "model",
inference_opts = list(method = "MCMC", samples = 6000, burn = 2000, verbose = T)
)
## distribution of noise
posterior.noise <- bda %>%
filter(Parameter %in% c("noise", "priorExponent"))
ggplot(posterior.noise, aes(x = value))+
geom_histogram()+
facet_wrap(~Parameter, scales = 'free')
## distribution of model predictions
posterior.predictive = bda %>%
filter(!(Parameter %in% c("noise", "priorExponent"))) %>%
separate(Parameter, into = c("Experiment", "Change", "Alignment"), sep="_")
ggplot(posterior.predictive, aes(x = value))+
geom_histogram(binwidth = .01)+
facet_wrap(~Experiment+Change+Alignment, nrow = 2,scales = 'free')
## Bayesian credible intervals
library(coda)
estimate_mode <- function(s) {
d <- density(s)
return(d$x[which.max(d$y)])
}
hdi_upper<- function(s){
m <- HPDinterval(mcmc(s))
return(m["var1","upper"])
}
hdi_lower<- function(s){
m <- HPDinterval(mcmc(s))
return(m["var1","lower"])
}
noisy.rsa.model <- posterior.predictive %>%
mutate(Model="Noisy RSA Model",
Adjustment = "Noise",
Type = "RSA")%>%
group_by(Model,Adjustment,Type,Experiment,Change,Alignment) %>%
summarise(mean = estimate_mode(value), ci_lower = hdi_lower(value), ci_upper = hdi_upper(value))
bda1 <- webppl(
program_code = paste(rsaUtils, rsaModel2, bdaModel.prior.noise, sep='\n'),
data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs),
data_var = "dataFromR",
model_var = "model",
inference_opts = list(method = "MCMC", samples = 6000, burn = 2000, verbose = T)
)
## distribution of noise
posterior.noise1 <- bda1 %>%
filter(Parameter %in% c("noise", "priorExponent"))
ggplot(posterior.noise1, aes(x = value))+
geom_histogram()+
facet_wrap(~Parameter, scales = 'free')
## distribution of model predictions
posterior.predictive1 = bda1 %>%
filter(!(Parameter %in% c("noise", "priorExponent"))) %>%
separate(Parameter, into = c("Experiment", "Change", "Alignment"), sep="_")
ggplot(posterior.predictive1, aes(x = value))+
geom_histogram(binwidth = .01)+
facet_wrap(~Experiment+Change+Alignment, nrow = 2,scales = 'free')
noisy.prior.model <- posterior.predictive1 %>%
mutate(Model="Noisy Prior Model",
Adjustment = "Noise",
Type = "Prior only")%>%
group_by(Model,Adjustment,Type,Experiment,Change,Alignment) %>%
summarise(mean = estimate_mode(value), ci_lower = hdi_lower(value), ci_upper = hdi_upper(value))
bda2 <- webppl(
program_code = paste(rsaUtils, rsaModel2, bdaModel.rsa.regularizedPrior, sep='\n'),
data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs),
data_var = "dataFromR",
model_var = "model",
inference_opts = list(method = "MCMC", samples = 6000, burn = 2000, verbose = T)
)
## distribution of noise
posterior.noise2 <- bda2 %>%
filter(Parameter %in% c("noise", "priorExponent"))
ggplot(posterior.noise2, aes(x = value))+
geom_histogram()+
facet_wrap(~Parameter, scales = 'free')
## distribution of model predictions
posterior.predictive2 = bda2 %>%
filter(!(Parameter %in% c("noise", "priorExponent"))) %>%
separate(Parameter, into = c("Experiment", "Change", "Alignment"), sep="_")
ggplot(posterior.predictive2, aes(x = value))+
geom_histogram(binwidth = .01)+
facet_wrap(~Experiment+Change+Alignment, nrow = 2,scales = 'free')
a = 1
a
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(ggthemes)
library(langcog)
library(rwebppl)
ggplot(llh.plot, aes(x = Model, y = logSumExp, fill = Model))+
geom_bar(stat="identity", color = "black")+
ggtitle("logsumexp per model")+
theme_few()+
theme(axis.text.x=element_text(angle = 45, vjust = 1, hjust = 1))
library(coda)
estimate_mode <- function(s) {
d <- density(s)
return(d$x[which.max(d$y)])
}
hdi_upper<- function(s){
m <- HPDinterval(mcmc(s))
return(m["var1","upper"])
}
hdi_lower<- function(s){
m <- HPDinterval(mcmc(s))
return(m["var1","lower"])
}
ggplot(data = plot.model,aes(x = mean, y = Data, col = Model)) +
geom_abline(intercept = 0, slope = 1, lty = 2, alpha = 0.3)+
geom_point()+
facet_grid(Type~Adjustment)+
coord_fixed()+
xlim(0,1)+ylim(0,1)+
xlab("Model")+
stat_cor(method = "pearson", label.x = 0.4, label.y = 0.9)+
geom_smooth(method = "lm", se = F, col = "black", size =0.4)+
theme_few() +
guides(col = F)+
scale_colour_solarized()
ggplot(p.com,
aes(x = Change, y = mean, fill = Alignment)) +
geom_bar(stat="identity", position = position_dodge(), color = 'black') +
geom_hline(yintercept = 0.5, lty=2)+
geom_linerange(aes(ymin = ci_lower, ymax = ci_upper),position = position_dodge(width = 0.9))+
labs(x=" ",y="Proportion Choosing More Informative")+
facet_grid(Experiment ~ Adjustment*Type, labeller = label_wrap_gen(width=5))+
theme_few(base_size = 12) +
theme(axis.text.x=element_text(angle = 45, vjust = 1, hjust = 1))+
ylim(0,1)
library(tidyverse)
library(ggpubr)
library(ggthemes)
