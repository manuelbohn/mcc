---
title: "MCC Model Predictions"
author: "Manuel Bohn"
date: "15 6 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

load("model.predictions.RData")

library(tidyverse)
library(knitr)
library(ggthemes)
library(langcog)
library(rwebppl)
library(coda)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}

```


```{r rsaUtils, include = FALSE}
rsaUtils <- '
var all_objects = [
{ shape: "triangle", id:1, location: 1},  
{ shape: "triangle", id:2, location: 2},
{ shape: "circle", id:1, location: 2}
]

var labels = ["dax","wug"]

var lexicon1 = function(utterance, obj){
utterance.label == "dax" ? obj.shape == "triangle" :
utterance.label == "wug" ? obj.shape == "circle" : 
true
}

var lexicon2 = function(utterance, obj){
utterance.label == "dax" ? obj.shape == "circle" :
utterance.label == "wug" ? obj.shape == "triangle" : 
true
}

var lexiconObjects = {
"dax = triangle": {
triangle: "dax", circle: "wug"
},
"dax = circle": {
triangle: "wug", circle: "dax"
},
}

var lexiconObject = {
"dax = triangle": lexicon1,
"dax = circle" : lexicon2
}

var point = function(utterance, obj){
return obj.location == utterance.point
}


var utterancePrior = function(obj, lexiconName){
var locationsWithShape = _.map(_.filter(all_objects, {shape: obj.shape}), "location")
var point = uniformDraw(locationsWithShape)
var label = lexiconObjects[lexiconName][obj.shape]
return {label: label, point: point}
}

var LexiconPrior = Categorical({vs: ["dax = triangle","dax = circle" ], ps: [1, 1]})
'
```

```{r rsaModel}
rsaModel <- 'var ObjectPrior = Categorical({vs: all_objects, ps: priorProbs })

var pragmaticListener = function(utterance){
Infer({method: "enumerate", model: function(){
var lexiconName = sample(LexiconPrior);
var obj = sample(ObjectPrior);
var S1 = speaker(obj, lexiconName);
observe(S1, utterance)
return {lexicon: lexiconName, obj: obj.shape}
}})
}

var speakerOptimality = 2.25;

var speaker = function(obj, lexiconName){
Infer({method: "enumerate", model: function(){
var utterance = utterancePrior(obj, lexiconName);
var L0 = literalListener(utterance);
 factor(speakerOptimality * L0.score(obj.shape))
return utterance
}})
}

var literalListener = function(utterance){
Infer({method: "enumerate", model: function(){
var lexiconName = sample(LexiconPrior); 
var lexicon = lexiconObject[lexiconName];
var obj = sample(ObjectPrior);
if ("label" in utterance) {
 var truthValue = lexicon(utterance, obj);
 condition(truthValue)
}
if (utterance.point) {
 var truthValuePoint = point(utterance, obj);
 condition(truthValuePoint)
}
return obj.shape 
}})
}


pragmaticListener({label: "dax", point: 2 })
'
```

```{r rsa model2, include = FALSE}
rsaModel2 <- '
var pragmaticListener = function(utterance, priorProbs){
Infer({method: "enumerate", model: function(){
var lexiconName = sample(LexiconPrior);
var obj = sample( Categorical({vs: all_objects, ps: priorProbs}));
var S1 = speaker(obj, lexiconName, priorProbs);
observe(S1, utterance)
return obj.shape == "circle" ? 1 : 0
}})
}

var speakerOptimality = 2.25;

var speaker = function(obj, lexiconName, priorProbs){
Infer({method: "enumerate", model: function(){
var utterance = utterancePrior(obj, lexiconName);
var L0 = literalListener(utterance, priorProbs);
 factor(speakerOptimality * L0.score(obj.shape))
return utterance
}})
}

var literalListener = function(utterance, priorProbs){
Infer({method: "enumerate", model: function(){
var lexiconName = sample(LexiconPrior); 
var lexicon = lexiconObject[lexiconName];
var obj = sample( Categorical({vs: all_objects, ps: priorProbs}));
if ("label" in utterance) {
 var truthValue = lexicon(utterance, obj);
 condition(truthValue)
}
if (utterance.point) {
 var truthValuePoint = point(utterance, obj);
 condition(truthValuePoint)
}
return obj.shape 
}})
}

var addNoise = function(dist, noiseParam){
   Infer({model: function(){ 
      return flip(noiseParam) ? uniformDraw([0, 1]) : sample(dist)
    }
   })
}
'
```

```{r predictions rsa noise, include = FALSE}
predictions.rsa.noise <-'
var allConditions = dataFromR.newConditions
var allData = dataFromR.predData
var allPriorProbs = dataFromR.predPriorProbs

var model = function(){
   var noise = uniformDrift({a: 0, b:1, width: 0.1})

  var conditionOutput = map(function(conditionInfo){

  var conditionSpecificData =  _.filter(allData, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment, Prior :"Strong"})

   var conditionSpecificPriors =  _.filter(allPriorProbs, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment, Prior :"Strong"})

   var modelPredictions = pragmaticListener({label: "dax", point: 2 }, conditionSpecificPriors[0].priorProbs)
   var noisyModelPredictions = addNoise(modelPredictions, noise)

   map(function(d){ 
      observe(noisyModelPredictions, d.correct_inf)
    }, conditionSpecificData)


  return  [conditionInfo.Experiment + "_" + conditionInfo.Change + "_" +  conditionInfo.Alignment+ "_" + conditionInfo.Prior, Math.exp(noisyModelPredictions.score(1))]

}, allConditions)

 // return extend(_.fromPairs(conditionOutput), {noise: noise})


// generate predictions for new conditions

   var newPredictions = map(function(conditionInfo){

    var newSpecificPriors =  _.filter(allPriorProbs, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment, Prior: conditionInfo.Prior})

    var newModelPredictions = pragmaticListener({label: "dax", point: 2 }, newSpecificPriors[0].priorProbs)
    var newNoisyModelPredictions = addNoise(newModelPredictions, noise)

    return  [conditionInfo.Experiment + "_" + conditionInfo.Change + "_" +  conditionInfo.Alignment + "_" + conditionInfo.Prior, Math.exp(newNoisyModelPredictions.score(1))]

  }, allConditions)

  return extend(_.fromPairs(newPredictions), {noise: noise})


}
'
```

```{r model setup, include = FALSE}


strongPriorProbs <- data.frame(
  Experiment = c("Preference","Preference","Preference","Preference","Novelty","Novelty","Novelty","Novelty"),
  Change = c("Same speaker","Same speaker","Different speaker","Different speaker","Same speaker","Same speaker","Different speaker","Different speaker"),
  Alignment = c("Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent"),
  Prior = rep("Strong",8))

strongPriorProbs$priorProbs = list(
    c(0.0333333, 0.033333, 0.9666667), 
    c(0.9666667, 0.9666667, 0.0333333),
    c(0.3583333, 0.3583333, 0.6416667),
    c(0.6416667, 0.6416667, 0.3583333),
    c(0.1666667, 0.1666667, 0.8333333),
    c(0.8333333, 0.8333333, 0.1666667),
    c(0.4083333, 0.4083333, 0.5916667),
    c(0.5916667, 0.5916667, 0.4083333))

mediumPriorProbs <- data.frame(
  Experiment = c("Preference","Preference","Preference","Preference","Novelty","Novelty","Novelty","Novelty"),
  Change = c("Same speaker","Same speaker","Different speaker","Different speaker","Same speaker","Same speaker","Different speaker","Different speaker"),
  Alignment = c("Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent"),
  Prior = rep("Medium",8))

mediumPriorProbs$priorProbs = list(
    c(0.1465517, 0.1465517, 0.8534483), 
    c(0.8534483, 0.8534483, 0.1465517),
    c(0.4137931, 0.4137931, 0.5862069),
    c(0.5862069, 0.5862069, 0.4137931),
    c(0.2983871, 0.2983871, 0.7016129),
    c(0.7016129, 0.7016129, 0.2983871),
    c(0.4137931, 0.4137931, 0.5862069),
    c(0.5862069, 0.5862069, 0.4137931))


weakPriorProbs <- data.frame(
  Experiment = c("Novelty","Novelty","Novelty","Novelty"),
  Change = c("Same speaker","Same speaker","Different speaker","Different speaker"),
  Alignment = c("Congruent","Incongruent","Congruent","Incongruent"),
  Prior = rep("Weak",4))

weakPriorProbs$priorProbs = list(
  c(0.4166667, 0.4166667, 0.5833333), 
  c(0.5833333, 0.5833333, 0.4166667),
  c(0.475, 0.475, 0.5250000),
  c(0.5250000, 0.5250000, 0.475))


predPriorProbs = rbind(strongPriorProbs,mediumPriorProbs,weakPriorProbs)

allPriorProbs <- strongPriorProbs %>%
  select(-Prior)

allConditions <- predPriorProbs %>%
  filter(Prior == "Strong")%>%
  select(-priorProbs, -Prior)

newConditions <- predPriorProbs %>%
  select(-priorProbs)

predData <- data %>%
  mutate(Prior = "Strong")
```

```{r predictions rsa noise, include = FALSE}
bda.pred.noise <- webppl(
  program_code = paste(rsaUtils, rsaModel2, predictions.rsa.noise, sep='\n'),
  data = list(allData = data, newConditions = newConditions, predPriorProbs = predPriorProbs, predData = predData), 
  data_var = "dataFromR",
  model_var = "model",
  inference_opts = list(method = "MCMC", samples = 10000, burn = 2000, verbose = T)
)


## distribution of noise
posterior.noise.pred <- bda.pred.noise %>%
  filter(Parameter %in% c("noise", "priorExponent"))

ggplot(posterior.noise.pred, aes(x = value))+
  geom_histogram()+
  facet_wrap(~Parameter, scales = 'free')

# model predictions

noisy.rsa.pred <- bda.pred.noise %>%
  filter(!(Parameter %in% c("noise", "priorExponent")))  %>%
  separate(Parameter, into = c("Experiment", "Change", "Alignment", "Prior"), sep="_")%>%
  mutate(Model="Noisy RSA Model",
         Adjustment = "Noise",
         Type = "RSA",
         Prior = relevel(as.factor(Prior), ref = "Weak"))%>%
  group_by(Model,Prior,Adjustment,Type,Experiment,Change,Alignment) %>%
  summarise(mean = estimate_mode(value), ci_lower = hdi_lower(value), ci_upper = hdi_upper(value))


```


```{r}

ggplot(noisy.rsa.pred, 
       aes(x = Change, y = mean, fill = Alignment)) +
  geom_bar(stat="identity", position = position_dodge(), color = 'black') + 
  geom_hline(yintercept = 0.5, lty=2)+
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper),position = position_dodge(width = 0.9))+
  labs(x=" ",y="Proportion Choosing More Informative")+
  facet_grid(Experiment ~ Prior)+
  theme_few(base_size = 12) + 
  theme(axis.text.x=element_text(angle = 45, vjust = 1, hjust = 1))+
  ylim(0,1)
```

```{r}
save.image(file="model.predictions.RData")
```

