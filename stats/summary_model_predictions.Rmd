---
title: "MCC model predictions overview"
author: "Manuel Bohn"
date: "17 5 2018"
output: html_document
---

```{r, include = FALSE}
knitr::opts_chunk$set(echo=FALSE)
knitr::opts_chunk$set(warning=FALSE)
```


```{r, include = FALSE}
load("model.comparisons.RData")

library(tidyverse)
library(ggplot2)
library(ggpubr)
library(ggthemes)
library(coda)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
```


## All model predictions and data

```{r, include = FALSE}
a <- ggplot(p.com, 
       aes(x = Change, y = mean, fill = Alignment)) +
  geom_bar(stat="identity", position = position_dodge(), color = 'black') + 
  geom_hline(yintercept = 0.5, lty=2)+
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper),position = position_dodge(width = 0.9))+
  labs(x=" ",y="Proportion Choosing More Informative")+
  facet_grid(Experiment ~ Adjustment*Type, labeller = label_wrap_gen(width=5))+
  theme_few(base_size = 12) + 
  theme(axis.text.x=element_text(angle = 45, vjust = 1, hjust = 1))+
  ylim(0,1)+
  theme(legend.position="bottom")
```

```{r}
a
```


## Correlations between mocel predictions and data

```{r, include = FALSE}
b <-ggplot(data = plot.model,aes(x = mean, y = Data, col = Model)) +
  geom_abline(intercept = 0, slope = 1, lty = 2, alpha = 0.3)+
  geom_point()+
  facet_grid(Type~Adjustment)+
  coord_fixed()+
  xlim(0,1)+ylim(0,1)+
  xlab("Model")+
  stat_cor(method = "pearson", label.x = 0.4, label.y = 0.9)+
  geom_smooth(method = "lm", se = F, col = "black", size =0.4)+
  theme_few() + 
  guides(col = F)+
  scale_colour_solarized()
```

```{r}
b
```

## Prior only Model with Noise
Mean noise parameter with 95% Credible Interval: `r round(mean(posterior.noise1$value),2)` [`r round(hdi_lower(posterior.noise1$value),2)` : `r round(hdi_upper(posterior.noise1$value),2)`].

Model predictions: Very squashed (less extreme) compared to no adjustment predictions due to high noise parameter. 

Qualitatively, predictions change for different speaker - congruent (from above chance to chance).

## RSA Model with Noise
Noise parameter: `r round(mean(posterior.noise$value),2)` [`r round(hdi_lower(posterior.noise$value),2)` : `r round(hdi_upper(posterior.noise$value),2)`]

Model predictions: Slightly squashed compared to no adjustment predictions. 

Qualitatively predictions do not change.

## Prior only Model with regularized Priors
Prior Exponent: `r round(mean(posterior.noise3$value),2)` [`r round(hdi_lower(posterior.noise3$value),2)` : `r round(hdi_upper(posterior.noise3$value),2)`].

Model predictions: Again, very squashed (less extreme) compared to no adjustment predictions. Prior exponent parameter shows that priors are pulled towards uniform (and therefore to chance level). 

Qualitatively, predictions change again for different speaker - congruent (from above chance to below chance).

## RSA Model with regularized Priors
Prior Exponent: `r round(mean(posterior.noise2$value),2)` [`r round(hdi_lower(posterior.noise2$value),2)` : `r round(hdi_upper(posterior.noise2$value),2)`]

Model predictions: Pulled strongly towards no prior model because priors are made more uniform. 

Qualitatively, predictions change for same speaker incongruent in novelty (from below chance to chance) and for different speaker incongruent preference (at chance to above chance).

## Prior only Model with Noise and regularized Priors
Noise parameter: `r round(mean(posterior.noise5$value[posterior.noise5$Parameter =="noise"]),2)` [`r round(hdi_lower(posterior.noise5$value[posterior.noise5$Parameter =="noise"]),2)` : `r round(hdi_upper(posterior.noise5$value[posterior.noise5$Parameter =="noise"]),2)`].

Prior Exponent: `r round(mean(posterior.noise5$value[posterior.noise5$Parameter =="priorExponent"]),2)` [`r round(hdi_lower(posterior.noise5$value[posterior.noise5$Parameter =="priorExponent"]),2)` : `r round(hdi_upper(posterior.noise5$value[posterior.noise5$Parameter =="priorExponent"]),2)`].

Model predictions: Slightly squashed (less extreme). More noise compared to model with noise only adjustment. Prior exponent suggests that priors are made more extreme - probably due to high noise parameter. 

No qualitative change.

## RSA Model with Noise and regularized Priors
Mean noise parameter with 95% CrI: `r round(mean(posterior.noise4$value[posterior.noise4$Parameter =="noise"]),2)` [`r round(hdi_lower(posterior.noise4$value[posterior.noise4$Parameter =="noise"]),2)` : `r round(hdi_upper(posterior.noise4$value[posterior.noise4$Parameter =="noise"]),2)`].

Mean priorExponent with 95% CrI: `r round(mean(posterior.noise4$value[posterior.noise4$Parameter =="priorExponent"]),2)` [`r round(hdi_lower(posterior.noise4$value[posterior.noise4$Parameter =="priorExponent"]),2)` : `r round(hdi_upper(posterior.noise4$value[posterior.noise4$Parameter =="priorExponent"]),2)`].

Model predictions: Slightly squashed (less extreme). A little less noisy compared to model with only noise adjustment. Prior adjustment is also less strongly towards uniform. 

No qualitative change.

## Comparing models
```{r model predictions log likelihood, include = FALSE}
c <- ggplot(llh.plot, aes(x = Model, y = logSumExp, fill = Model))+
  geom_bar(stat="identity", color = "black")+
  ggtitle("logsumexp per model")+
  theme_few()+ 
  theme(axis.text.x=element_text(angle = 45, vjust = 1, hjust = 1))
```

```{r}
llh.plot%>%
  knitr::kable(digits = 3)
```


```{r}
c
```




