---
title: "MCC Predictions"
author: "Manuel Bohn"
date: "9 4 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(knitr)
library(ggthemes)
library(langcog)
```

# Modeling Informativeness

Speaker optimality parameter of 2.25 produces model predictions that match our empirical results. The following predictions therefore use this parameter.

Prior = measured proportion this type of object is being chosen.

## "Dampening"" model

### Preference inconcgruent
ObjectPrior = Categorical({vs: all_objects, ps: [0.9666667, 0.9666667, 0.0333333] })


### Preference congruent
ObjectPrior = Categorical({vs: all_objects, ps: [0.0333333, 0.0333333, 0.9666667] })


### Novelty inconcgruent
var ObjectPrior = Categorical({vs: all_objects, ps: [0.8333333, 0.8333333, 0.1666667] })


### Novelty concgruent
var ObjectPrior = Categorical({vs: all_objects, ps: [0.1666667, 0.1666667, 0.8333333] })


```{r data}
dat <- bind_rows(read_csv(file="ex3.novel.data.csv"),
               read_csv(file="ex3.pref.data.csv")) %>%
  mutate(trial_type = ifelse(trial == "train1" | trial =="train2", "train", "test"))
```


```{r sanity checks}
# check if there are incongruent trials in which informativeness and prior yield the same results
# is not the case, that's good
dat %>%
  filter(alignment == "incongruent") %>%
  filter(correct_inf == correct_prior)


# check if someone needs to be excluded because wrong in training
# no one, that's good
dat %>%
  filter(trial_type == "train") %>%
  group_by(id)%>%
  summarise(correct_inf = mean(correct_inf)) %>%
  filter(correct_inf == 0)
  
# check if someone did both experiments
# yes, two people
x <- dat %>%
  filter(trial_type == "train") %>%
  group_by(id)%>%
  summarise(n = length(correct_inf)) %>%
  filter(n > 2)

# exclude those who did both experiments
data <- dat %>%
  filter(!id %in% x$id) %>%
  filter(trial_type != "train") %>%
  mutate(Change = ifelse(change =="same", "Same speaker", "Different speaker"),
         Alignment = ifelse(alignment == "congruent", "Congruent", "Incongruent"),
         Experiment = ifelse(experiment == "pref_inf", "Preference", "Novelty"))


data %>%
  group_by(experiment,alignment,change) %>%
  summarise(n = length(id))

```

```{r plot data}

p1 <- data %>%
  filter(trial_type == "test") %>%
  group_by(Change ,Experiment,Alignment, id) %>%
  summarise(correct = mean(correct_inf)) 

p2 <- p1 %>%
  multi_boot_standard(col = "correct")


ggplot() +
  geom_jitter(data = p1, aes(x = Alignment, y = correct, col = Alignment, alpha = .2),width = .3,height = .025)+
  geom_pointrange(data = p2, aes(x = Alignment, y = mean, col = Alignment,ymin = ci_lower, ymax = ci_upper),size = .8)+
  geom_hline(yintercept = 0.5, lty=2)+
  labs(x="",y="Proportion Expected Choice")+
  facet_grid(Experiment ~ Change , scales = "free_x", space = "free_x" ) +
  theme_few() + 
  ylim(-0.05,1.05)+
  guides(alpha = F)+ 
  scale_colour_solarized()

```

```{r comparisons to chance}
library(exactRankTests)

data %>%  
  filter(trial_type == "test") %>%
  group_by(change ,experiment,alignment, id) %>%
  summarise(correct_inf = mean(correct_inf)) %>%
  summarize(correct_inf = list(correct_inf)) %>%
  group_by(change ,experiment,alignment) %>%
  mutate(mean = mean(unlist(correct_inf)),
         stat = wilcox.exact(unlist(correct_inf), mu = 0.5)$statistic,
         p_value = wilcox.exact(unlist(correct_inf), mu = 0.5)$p.value) %>%
  select(change ,experiment,alignment,mean,stat,p_value)%>%
  knitr::kable(digits = 3)
```


```{r model}
library(lme4)

m.data <- data %>%
  mutate(item = ifelse( change == "false", agent, altAgent))


lm <- glmer(correct_inf ~ Experiment*Change*Alignment + (Change*Alignment|id) + (Change+Alignment|agent), 
              data = m.data, family = binomial, 
              control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))

summary(lm)


```



```{r model predictions}
predictions <- data.frame(
  Experiment = c("Preference","Preference","Preference","Preference","Novelty","Novelty","Novelty","Novelty","Preference","Preference","Preference","Preference","Novelty","Novelty","Novelty","Novelty","Preference","Preference","Preference","Preference","Novelty","Novelty","Novelty","Novelty"),
  Change = c("Same speaker","Same speaker","Different speaker","Different speaker","Same speaker","Same speaker","Different speaker","Different speaker","Same speaker","Same speaker","Different speaker","Different speaker","Same speaker","Same speaker","Different speaker","Different speaker","Same speaker","Same speaker","Different speaker","Different speaker","Same speaker","Same speaker","Different speaker","Different speaker"),
  Alignment = c("Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent"),
  Model = c("Full model","Full model","Full model","Full model","Full model","Full model","Full model","Full model","No prior","No prior","No prior","No prior","No prior","No prior","No prior","No prior", "Prior only","Prior only","Prior only","Prior only","Prior only","Prior only","Prior only","Prior only"),
  corr = c(0.9999672744165804,0.03460862921907267,0.9083230583454356,0.5090645649737232,0.9930727540990627,0.20045767964927574,0.8603373265403738,0.594975610001643,0.742,0.742,0.742,0.742,0.742,0.742,0.742,0.742,0.967,0.033,0.642,0.358,0.833,0.167,0.592,0.408)) 


pred <- predictions %>%
  group_by(Model,Experiment,Change,Alignment)%>%
  multi_boot_standard(col = "corr")

```

```{r joining files}

da <- data %>%
  filter(trial_type=="test")%>%
  mutate(Change = ifelse(change =="same", "Same speaker", "Different speaker"),
         Alignment = ifelse(alignment == "congruent", "Congruent", "Incongruent"),
         Experiment = ifelse(experiment == "pref_inf", "Preference", "Novelty"),
         Model = "Data") %>%
  group_by(Model,Experiment,Change,Alignment,id)%>%
  summarise(correct_inf = mean(correct_inf)) %>%
  multi_boot_standard(col = "correct_inf")


pd <- rbind(pred,da)

```


```{r plot models and data}

ggplot(pd, 
       aes(x = Change, y = mean, fill = Alignment)) +
  geom_bar(stat="identity", position = position_dodge(), color = 'black') + 
  geom_hline(yintercept = 0.5, lty=2)+
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper),position = position_dodge(width = 0.9))+
  labs(x=" ",y="Proportion Choosing More Informative")+
  facet_grid(Experiment ~ Model)+
  theme_few(base_size = 12) + 
  theme(axis.text.x=element_text(angle = 45, vjust = 1, hjust = 1))+
  ylim(0,1)

```
```{r plot comparing models}

library(ggpubr)

plot1 <- data.frame(pd$Experiment[pd$Model=="Data"],pd$mean[pd$Model=="Data"],pd$mean[pd$Model=="Prior only"],rep("Data vs Prior only",8))
names(plot1) = c("Experiment","Data","Model","Comp")
plot2 <- data.frame(pd$Experiment[pd$Model=="Data"],pd$mean[pd$Model=="Data"],pd$mean[pd$Model=="Full model"],rep("Data vs Full model",8))
names(plot2) = c("Experiment","Data","Model","Comp")

plot <- rbind(plot1,plot2)

ggplot(data = plot,aes(x = Model, y = Data, col = Comp)) +
  geom_abline(intercept = 0, slope = 1, lty = 2, alpha = 0.3)+
  geom_point()+
  coord_fixed()+
  xlim(0,1)+ylim(0,1)+
  facet_grid(~Comp)+
  stat_cor(method = "pearson", label.x = 0.4, label.y = 0.9)+
  geom_smooth(method = "lm", se = F, col = "black")+
  theme_few() + 
  guides(col = F)+
  scale_colour_solarized()


```




```{r rsaUtils}
library(rwebppl)

rsaUtils <- '
var all_objects = [
{ shape: "triangle", id:1, location: 1},  
{ shape: "triangle", id:2, location: 2},
{ shape: "circle", id:1, location: 2}
]

var labels = ["dax","wug"]

var lexicon1 = function(utterance, obj){
utterance.label == "dax" ? obj.shape == "triangle" :
utterance.label == "wug" ? obj.shape == "circle" : 
true
}

var lexicon2 = function(utterance, obj){
utterance.label == "dax" ? obj.shape == "circle" :
utterance.label == "wug" ? obj.shape == "triangle" : 
true
}

var lexiconObjects = {
"dax = triangle": {
triangle: "dax", circle: "wug"
},
"dax = circle": {
triangle: "wug", circle: "dax"
},
}

var lexiconObject = {
"dax = triangle": lexicon1,
"dax = circle" : lexicon2
}

var point = function(utterance, obj){
return obj.location == utterance.point
}


var utterancePrior = function(obj, lexiconName){
var locationsWithShape = _.map(_.filter(all_objects, {shape: obj.shape}), "location")
var point = uniformDraw(locationsWithShape)
var label = lexiconObjects[lexiconName][obj.shape]
return {label: label, point: point}
}

var LexiconPrior = Categorical({vs: ["dax = triangle","dax = circle" ], ps: [1, 1]})
'
```

```{r rsaModel}
rsaModel <- 'var ObjectPrior = Categorical({vs: all_objects, ps: priorProbs })

var pragmaticListener = function(utterance){
Infer({method: "enumerate", model: function(){
var lexiconName = sample(LexiconPrior);
var obj = sample(ObjectPrior);
var S1 = speaker(obj, lexiconName);
observe(S1, utterance)
return {lexicon: lexiconName, obj: obj.shape}
}})
}

var speakerOptimality = 2.25;

var speaker = function(obj, lexiconName){
Infer({method: "enumerate", model: function(){
var utterance = utterancePrior(obj, lexiconName);
var L0 = literalListener(utterance);
 factor(speakerOptimality * L0.score(obj.shape))
return utterance
}})
}

var literalListener = function(utterance){
Infer({method: "enumerate", model: function(){
var lexiconName = sample(LexiconPrior); 
var lexicon = lexiconObject[lexiconName];
var obj = sample(ObjectPrior);
if ("label" in utterance) {
 var truthValue = lexicon(utterance, obj);
 condition(truthValue)
}
if (utterance.point) {
 var truthValuePoint = point(utterance, obj);
 condition(truthValuePoint)
}
return obj.shape 
}})
}


pragmaticListener({label: "dax", point: 2 })
'
```

```{r rsa model2}
rsaModel2 <- '
var pragmaticListener = function(utterance, priorProbs){
Infer({method: "enumerate", model: function(){
var lexiconName = sample(LexiconPrior);
var obj = sample( Categorical({vs: all_objects, ps: priorProbs}));
var S1 = speaker(obj, lexiconName, priorProbs);
observe(S1, utterance)
return obj.shape == "circle" ? 1 : 0
}})
}

var speakerOptimality = 2.25;

var speaker = function(obj, lexiconName, priorProbs){
Infer({method: "enumerate", model: function(){
var utterance = utterancePrior(obj, lexiconName);
var L0 = literalListener(utterance, priorProbs);
 factor(speakerOptimality * L0.score(obj.shape))
return utterance
}})
}

var literalListener = function(utterance, priorProbs){
Infer({method: "enumerate", model: function(){
var lexiconName = sample(LexiconPrior); 
var lexicon = lexiconObject[lexiconName];
var obj = sample( Categorical({vs: all_objects, ps: priorProbs}));
if ("label" in utterance) {
 var truthValue = lexicon(utterance, obj);
 condition(truthValue)
}
if (utterance.point) {
 var truthValuePoint = point(utterance, obj);
 condition(truthValuePoint)
}
return obj.shape 
}})
}

var addNoise = function(dist, noiseParam){
   Infer({model: function(){ 
      return flip(noiseParam) ? uniformDraw([0, 1]) : sample(dist)
    }
   })
}
'
```

```{r bda model rsa noise}
bdaModel.rsa.noise <-'
var allConditions = dataFromR.allConditions
var allData = dataFromR.allData
var allPriorProbs = dataFromR.allPriorProbs

var model = function(){
   var noise = uniformDrift({a: 0, b:1, width: 0.1})

  var conditionOutput = map(function(conditionInfo){

  var conditionSpecificData =  _.filter(allData, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})

   var conditionSpecificPriors =  _.filter(allPriorProbs, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})

  //display(JSON.stringify(conditionSpecificData[0].correct_inf))

   var modelPredictions = pragmaticListener({label: "dax", point: 2 }, conditionSpecificPriors[0].priorProbs)
   var noisyModelPredictions = addNoise(modelPredictions, noise)

   map(function(d){ 
     // display(JSON.stringify(noisyModelPredictions) + JSON.stringify(d.correct_inf))
      observe(noisyModelPredictions, d.correct_inf)
    }, conditionSpecificData)


  return  [conditionInfo.Experiment + "_" + conditionInfo.Change + "_" +  conditionInfo.Alignment, Math.exp(noisyModelPredictions.score(1))]

}, allConditions)

 return extend(_.fromPairs(conditionOutput), {noise: noise})
}
'
```

```{r bda model prior noise}
bdaModel.prior.noise <-'
var allConditions = dataFromR.allConditions
var allData = dataFromR.allData
var allPriorProbs = dataFromR.allPriorProbs

var model = function(){
   var noise = uniformDrift({a: 0, b:1, width: 0.1})

  var conditionOutput = map(function(conditionInfo){

  var conditionSpecificData =  _.filter(allData, 
        {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})

   var conditionSpecificPriors =  _.filter(allPriorProbs, 
        {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})

  //display(JSON.stringify(conditionSpecificData[0].correct_inf))

    var priorOnlyPredictions = Infer({method: "enumerate", model: function(){
      var obj = sample( Categorical({vs: all_objects, ps: conditionSpecificPriors[0].priorProbs}));
      return obj.shape == "circle" ? 1 : 0
    }})

   var noisyModelPredictions = addNoise(priorOnlyPredictions, noise)

   map(function(d){ 
     // display(JSON.stringify(noisyModelPredictions) + JSON.stringify(d.correct_inf))
      observe(noisyModelPredictions, d.correct_inf)
    }, conditionSpecificData)


  return  [conditionInfo.Experiment + "_" + conditionInfo.Change + "_" +  conditionInfo.Alignment, Math.exp(noisyModelPredictions.score(1))]

}, allConditions)

 return extend(_.fromPairs(conditionOutput), {noise: noise})
}
'
```

```{r bda model rsa regularizedPrior}
bdaModel.rsa.regularizedPrior <-'
var allConditions = dataFromR.allConditions
var allData = dataFromR.allData
var allPriorProbs = dataFromR.allPriorProbs

var model = function(){
   var priorExponent = uniformDrift({a: 0, b:5, width: 0.1})

  var conditionOutput = map(function(conditionInfo){

  var conditionSpecificData =  _.filter(allData, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})

   var conditionSpecificPriors =  _.filter(allPriorProbs, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})

  var regularizedPriors = normalize(map(function(i){ return Math.pow(i, priorExponent) },
        conditionSpecificPriors[0].priorProbs))

  //display(JSON.stringify(conditionSpecificData[0].correct_inf))

   var modelPredictions = pragmaticListener({label: "dax", point: 2 }, regularizedPriors)

   map(function(d){ 
     // display(JSON.stringify(modelPredictions) + JSON.stringify(d.correct_inf))
      observe(modelPredictions, d.correct_inf)
      // factor(modelPredictions.score(d.correct_inf))
    }, conditionSpecificData)


  return  [conditionInfo.Experiment + "_" + conditionInfo.Change + "_" +  conditionInfo.Alignment, Math.exp(modelPredictions.score(1))]

}, allConditions)

 return extend(_.fromPairs(conditionOutput), {priorExponent: priorExponent})
}
'
```

```{r bda model prior regularizedPrior}
bdaModel.prior.regularizedPrior <-'
var allConditions = dataFromR.allConditions
var allData = dataFromR.allData
var allPriorProbs = dataFromR.allPriorProbs

var model = function(){
   var priorExponent = uniformDrift({a: 0, b:5, width: 0.1})

  var conditionOutput = map(function(conditionInfo){

  var conditionSpecificData =  _.filter(allData, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})

   var conditionSpecificPriors =  _.filter(allPriorProbs, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})

  var regularizedPriors = normalize(map(function(i){ return Math.pow(i, priorExponent) },
        conditionSpecificPriors[0].priorProbs))

  //display(JSON.stringify(conditionSpecificData[0].correct_inf))

    var modelPredictions = Infer({method: "enumerate", model: function(){
      var obj = sample( Categorical({vs: all_objects, ps: regularizedPriors}));
      return obj.shape == "circle" ? 1 : 0
    }})

   map(function(d){ 
     // display(JSON.stringify(modelPredictions) + JSON.stringify(d.correct_inf))
      observe(modelPredictions, d.correct_inf)
      // factor(modelPredictions.score(d.correct_inf))
    }, conditionSpecificData)


  return  [conditionInfo.Experiment + "_" + conditionInfo.Change + "_" +  conditionInfo.Alignment, Math.exp(modelPredictions.score(1))]

}, allConditions)

 return extend(_.fromPairs(conditionOutput), {priorExponent: priorExponent})
}
'
```

```{r bda model rsa regularizedPrior noise}
bdaModel.rsa.regularizedPrior.noise <-'
var allConditions = dataFromR.allConditions
var allData = dataFromR.allData
var allPriorProbs = dataFromR.allPriorProbs

var model = function(){
   var priorExponent = uniformDrift({a: 0, b:5, width: 0.1})
   var noise = uniformDrift({a: 0, b:1, width: 0.1})

  var conditionOutput = map(function(conditionInfo){

  var conditionSpecificData =  _.filter(allData, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})

   var conditionSpecificPriors =  _.filter(allPriorProbs, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})

  var regularizedPriors = normalize(map(function(i){ return Math.pow(i, priorExponent) },
        conditionSpecificPriors[0].priorProbs))

  //display(JSON.stringify(conditionSpecificData[0].correct_inf))

   var modelPredictions = pragmaticListener({label: "dax", point: 2 }, regularizedPriors)
   var noisyModelPredictions = addNoise(modelPredictions, noise)

   map(function(d){ 
     // display(JSON.stringify(noisyModelPredictions) + JSON.stringify(d.correct_inf))
      observe(noisyModelPredictions, d.correct_inf)
    }, conditionSpecificData)


  return  [conditionInfo.Experiment + "_" + conditionInfo.Change + "_" +  conditionInfo.Alignment, Math.exp(noisyModelPredictions.score(1))]

}, allConditions)

 return extend(_.fromPairs(conditionOutput), {noise: noise, priorExponent: priorExponent})
}
'
```

```{r bda model prior regularizedPrior noise}
bdaModel.prior.regularizedPrior.noise <-'
var allConditions = dataFromR.allConditions
var allData = dataFromR.allData
var allPriorProbs = dataFromR.allPriorProbs

var model = function(){
   var priorExponent = uniformDrift({a: 0, b:5, width: 0.1})
   var noise = uniformDrift({a: 0, b:1, width: 0.1})

  var conditionOutput = map(function(conditionInfo){

  var conditionSpecificData =  _.filter(allData, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})

   var conditionSpecificPriors =  _.filter(allPriorProbs, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})

  var regularizedPriors = normalize(map(function(i){ return Math.pow(i, priorExponent) },
        conditionSpecificPriors[0].priorProbs))

  //display(JSON.stringify(conditionSpecificData[0].correct_inf))

  var modelPredictions = Infer({method: "enumerate", model: function(){
      var obj = sample( Categorical({vs: all_objects, ps: regularizedPriors}));
      return obj.shape == "circle" ? 1 : 0
  }})

   var noisyModelPredictions = addNoise(modelPredictions, noise)

   map(function(d){ 
     // display(JSON.stringify(noisyModelPredictions) + JSON.stringify(d.correct_inf))
      observe(noisyModelPredictions, d.correct_inf)
    }, conditionSpecificData)


  return  [conditionInfo.Experiment + "_" + conditionInfo.Change + "_" +  conditionInfo.Alignment, Math.exp(noisyModelPredictions.score(1))]

}, allConditions)

 return extend(_.fromPairs(conditionOutput), {noise: noise, priorExponent: priorExponent})
}
'
```

```{r model setup}

allConditions <- data %>%
  mutate(Change = ifelse(change =="same", "Same speaker", "Different speaker"),
         Alignment = ifelse(alignment == "congruent", "Congruent", "Incongruent"),
         Experiment = ifelse(experiment == "pref_inf", "Preference", "Novelty")) %>%
  group_by(Experiment,Change,Alignment)%>%
  summarise(correct_inf = mean(correct_inf)) %>%
  select(Change, Alignment,Experiment)

allPriorProbs <- data.frame(
  Experiment = c("Preference","Preference","Preference","Preference","Novelty","Novelty","Novelty","Novelty"),
  Change = c("Same speaker","Same speaker","Different speaker","Different speaker","Same speaker","Same speaker","Different speaker","Different speaker"),
  Alignment = c("Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent","Congruent","Incongruent"))

allPriorProbs$priorProbs = list(
    c(0.0333333, 0.033333, 0.9666667), 
    c(0.9666667, 0.9666667, 0.0333333),
    c(0.3583333, 0.3583333, 0.6416667),
    c(0.6416667, 0.6416667, 0.3583333),
    c(0.1666667, 0.1666667, 0.8333333),
    c(0.8333333, 0.8333333, 0.1666667),
    c(0.4083333, 0.4083333, 0.5916667),
    c(0.5916667, 0.5916667, 0.4083333))
```

```{r predictions rsa noise}
bda <- webppl(
  program_code = paste(rsaUtils, rsaModel2, bdaModel.rsa.noise, sep='\n'),
  data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs), 
  data_var = "dataFromR",
  model_var = "model",
  inference_opts = list(method = "MCMC", samples = 6000, burn = 2000, verbose = T)
)


## distribution of noise
posterior.noise <- bda %>%
  filter(Parameter %in% c("noise", "priorExponent"))

ggplot(posterior.noise, aes(x = value))+
  geom_histogram()+
  facet_wrap(~Parameter, scales = 'free')

## distribution of model predictions
posterior.predictive = bda %>%
  filter(!(Parameter %in% c("noise", "priorExponent"))) %>%
  separate(Parameter, into = c("Experiment", "Change", "Alignment"), sep="_")


ggplot(posterior.predictive, aes(x = value))+
  geom_histogram(binwidth = .01)+
  facet_wrap(~Experiment+Change+Alignment, nrow = 2,scales = 'free')


## Bayesian credible intervals

library(coda)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}


noisy.rsa.model <- posterior.predictive %>%
  mutate(Model="Noisy RSA Model",
         Adjustment = "Noise",
         Type = "RSA")%>%
  group_by(Model,Adjustment,Type,Experiment,Change,Alignment) %>%
  summarise(mean = estimate_mode(value), ci_lower = hdi_lower(value), ci_upper = hdi_upper(value))

```

```{r predictions prior noise}
bda1 <- webppl(
  program_code = paste(rsaUtils, rsaModel2, bdaModel.prior.noise, sep='\n'),
  data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs), 
  data_var = "dataFromR",
  model_var = "model",
  inference_opts = list(method = "MCMC", samples = 6000, burn = 2000, verbose = T)
)


## distribution of noise
posterior.noise1 <- bda1 %>%
  filter(Parameter %in% c("noise", "priorExponent"))

ggplot(posterior.noise1, aes(x = value))+
  geom_histogram()+
  facet_wrap(~Parameter, scales = 'free')

## distribution of model predictions
posterior.predictive1 = bda1 %>%
  filter(!(Parameter %in% c("noise", "priorExponent"))) %>%
  separate(Parameter, into = c("Experiment", "Change", "Alignment"), sep="_")


ggplot(posterior.predictive1, aes(x = value))+
  geom_histogram(binwidth = .01)+
  facet_wrap(~Experiment+Change+Alignment, nrow = 2,scales = 'free')


## Bayesian credible intervals

library(coda)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}


noisy.prior.model <- posterior.predictive1 %>%
  mutate(Model="Noisy Prior Model",
         Adjustment = "Noise",
         Type = "Prior only")%>%
  group_by(Model,Adjustment,Type,Experiment,Change,Alignment) %>%
  summarise(mean = estimate_mode(value), ci_lower = hdi_lower(value), ci_upper = hdi_upper(value))

```

```{r predictions rsa regularized prior}
bda2 <- webppl(
  program_code = paste(rsaUtils, rsaModel2, bdaModel.rsa.regularizedPrior, sep='\n'),
  data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs), 
  data_var = "dataFromR",
  model_var = "model",
  inference_opts = list(method = "MCMC", samples = 6000, burn = 2000, verbose = T)
)


## distribution of noise
posterior.noise2 <- bda2 %>%
  filter(Parameter %in% c("noise", "priorExponent"))

ggplot(posterior.noise2, aes(x = value))+
  geom_histogram()+
  facet_wrap(~Parameter, scales = 'free')

## distribution of model predictions
posterior.predictive2 = bda2 %>%
  filter(!(Parameter %in% c("noise", "priorExponent"))) %>%
  separate(Parameter, into = c("Experiment", "Change", "Alignment"), sep="_")


ggplot(posterior.predictive2, aes(x = value))+
  geom_histogram(binwidth = .01)+
  facet_wrap(~Experiment+Change+Alignment, nrow = 2,scales = 'free')


## Bayesian credible intervals

library(coda)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}


regPrior.rsa.model <- posterior.predictive2 %>%
  mutate(Model="Regularized RSA Model",
         Adjustment = "Regularized Prior",
         Type = "RSA")%>%
  group_by(Model,Adjustment,Type,Experiment,Change,Alignment) %>%
  summarise(mean = estimate_mode(value), ci_lower = hdi_lower(value), ci_upper = hdi_upper(value))

```

```{r predictions prior regularized prior}
bda3 <- webppl(
  program_code = paste(rsaUtils, rsaModel2, bdaModel.prior.regularizedPrior, sep='\n'),
  data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs), 
  data_var = "dataFromR",
  model_var = "model",
  inference_opts = list(method = "MCMC", samples = 6000, burn = 2000, verbose = T)
)


## distribution of noise
posterior.noise3 <- bda3 %>%
  filter(Parameter %in% c("noise", "priorExponent"))

ggplot(posterior.noise3, aes(x = value))+
  geom_histogram()+
  facet_wrap(~Parameter, scales = 'free')

## distribution of model predictions
posterior.predictive3 = bda3 %>%
  filter(!(Parameter %in% c("noise", "priorExponent"))) %>%
  separate(Parameter, into = c("Experiment", "Change", "Alignment"), sep="_")


ggplot(posterior.predictive3, aes(x = value))+
  geom_histogram(binwidth = .01)+
  facet_wrap(~Experiment+Change+Alignment, nrow = 2,scales = 'free')


## Bayesian credible intervals

library(coda)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}


regPrior.prior.model <- posterior.predictive3 %>%
  mutate(Model="Regularized Prior Model",
         Adjustment = "Regularized Prior",
         Type = "Prior only")%>%
  group_by(Model,Adjustment,Type,Experiment,Change,Alignment) %>%
  summarise(mean = estimate_mode(value), ci_lower = hdi_lower(value), ci_upper = hdi_upper(value))

```

```{r predictions rsa noise regularized prior}
bda4 <- webppl(
  program_code = paste(rsaUtils, rsaModel2, bdaModel.rsa.regularizedPrior.noise, sep='\n'),
  data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs), 
  data_var = "dataFromR",
  model_var = "model",
  inference_opts = list(method = "MCMC", samples = 6000, burn = 2000, verbose = T)
)


## distribution of noise
posterior.noise4 <- bda4 %>%
  filter(Parameter %in% c("noise", "priorExponent"))

ggplot(posterior.noise4, aes(x = value))+
  geom_histogram()+
  facet_wrap(~Parameter, scales = 'free')

## distribution of model predictions
posterior.predictive4 = bda4 %>%
  filter(!(Parameter %in% c("noise", "priorExponent"))) %>%
  separate(Parameter, into = c("Experiment", "Change", "Alignment"), sep="_")


ggplot(posterior.predictive4, aes(x = value))+
  geom_histogram(binwidth = .01)+
  facet_wrap(~Experiment+Change+Alignment, nrow = 2,scales = 'free')


## Bayesian credible intervals

library(coda)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}


noisy.regPrior.rsa.model <- posterior.predictive4 %>%
  mutate(Model="Noisy Regularized RSA Model",
         Adjustment = "Noise & Regularized Prior",
         Type = "RSA")%>%
  group_by(Model,Adjustment,Type,Experiment,Change,Alignment) %>%
  summarise(mean = estimate_mode(value), ci_lower = hdi_lower(value), ci_upper = hdi_upper(value))

```

```{r predictions prior noise regularized prior}
bda5 <- webppl(
  program_code = paste(rsaUtils, rsaModel2, bdaModel.prior.regularizedPrior.noise, sep='\n'),
  data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs), 
  data_var = "dataFromR",
  model_var = "model",
  inference_opts = list(method = "MCMC", samples = 6000, burn = 2000, verbose = T)
)


## distribution of noise
posterior.noise5 <- bda5 %>%
  filter(Parameter %in% c("noise", "priorExponent"))

ggplot(posterior.noise5, aes(x = value))+
  geom_histogram()+
  facet_wrap(~Parameter, scales = 'free')

## distribution of model predictions
posterior.predictive5 = bda5 %>%
  filter(!(Parameter %in% c("noise", "priorExponent"))) %>%
  separate(Parameter, into = c("Experiment", "Change", "Alignment"), sep="_")


ggplot(posterior.predictive5, aes(x = value))+
  geom_histogram(binwidth = .01)+
  facet_wrap(~Experiment+Change+Alignment, nrow = 2,scales = 'free')


## Bayesian credible intervals

library(coda)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}


noisy.regPrior.prior.model <- posterior.predictive5 %>%
  mutate(Model="Noisy Regularized Prior Model",
         Adjustment = "Noise & Regularized Prior",
         Type = "Prior only")%>%
  group_by(Model,Adjustment,Type,Experiment,Change,Alignment) %>%
  summarise(mean = estimate_mode(value), ci_lower = hdi_lower(value), ci_upper = hdi_upper(value))

```

```{r}
## joining noisy model predictions with other predictions
no.adj.models <- pd %>%
  mutate(Type = ifelse(Model == "Full model" | Model == "No prior","RSA",ifelse(Model == "Data","Data","Prior only")),
         Adjustment = "None")

p.com <- bind_rows(
  noisy.rsa.model,
  noisy.prior.model,
  regPrior.rsa.model,
  regPrior.prior.model,
  noisy.regPrior.rsa.model,
  noisy.regPrior.prior.model,
  no.adj.models
  )


ggplot(p.com, 
       aes(x = Change, y = mean, fill = Alignment)) +
  geom_bar(stat="identity", position = position_dodge(), color = 'black') + 
  geom_hline(yintercept = 0.5, lty=2)+
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper),position = position_dodge(width = 0.9))+
  labs(x=" ",y="Proportion Choosing More Informative")+
  facet_grid(Experiment ~ Model, labeller = label_wrap_gen(width=5))+
  theme_few(base_size = 12) + 
  theme(axis.text.x=element_text(angle = 45, vjust = 1, hjust = 1))+
  ylim(0,1)

```

```{r}
## correlations for model comparisons

p.com$Data = rep(pd$mean[pd$Model=="Data"],10)

plot.model <- p.com %>%
  filter(Model != "Data", Model != "No prior" )


ggplot(data = plot.model,aes(x = mean, y = Data, col = Model)) +
  geom_abline(intercept = 0, slope = 1, lty = 2, alpha = 0.3)+
  geom_point()+
  facet_grid(Type~Adjustment)+
  coord_fixed()+
  xlim(0,1)+ylim(0,1)+
  xlab("Model")+
  stat_cor(method = "pearson", label.x = 0.4, label.y = 0.9)+
  geom_smooth(method = "lm", se = F, col = "black", size =0.4)+
  theme_few() + 
  guides(col = F)+
  scale_colour_solarized()


```


```{r model rsa loglikelihood}
bdaModel.rsa.loglikelihood <-'
var allConditions = dataFromR.allConditions
var allData = dataFromR.allData
var allPriorProbs = dataFromR.allPriorProbs

var model = function(){
  
  var priorExponent = uniformDrift({a: 0, b:5, width: 0.1})

  var conditionOutput = map(function(conditionInfo){

  var conditionSpecificData =  _.filter(allData, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})

   var conditionSpecificPriors =  _.filter(allPriorProbs, {Experiment: conditionInfo.Experiment, Change: conditionInfo.Change, Alignment: conditionInfo.Alignment})

  var regularizedPriors = normalize(map(function(i){ return Math.pow(i, priorExponent) },
        conditionSpecificPriors[0].priorProbs))

   var modelPredictions = pragmaticListener({label: "dax", point: 2 }, regularizedPriors)

   var loglike = sum(map(function(d){ 

  //display(JSON.stringify(modelPredictions.score(d.correct_inf)))
  //display(JSON.stringify(conditionSpecificData))
      
  return modelPredictions.score(d.correct_inf)
    }, conditionSpecificData))

  return  loglike
}, allConditions)

 return sum(loglike)
}
'
```


```{r rsa loglikelihood}
llh <- webppl(
  program_code = paste(rsaUtils, rsaModel2, bdaModel.rsa.loglikelihood, sep='\n'),
  data = list(allData = data, allConditions = allConditions, allPriorProbs = allPriorProbs), 
  data_var = "dataFromR",
  model_var = "model",
  inference_opts = list(method = "forward", samples = 100, verbose = T)
)

```


```{r simple BF model comparisons}
priorProbsFromR <- list(
  "pref_inf_same_congruent" =  c(0.0333333, 0.033333, 0.9666667),
  "pref_inf_same_incongruent" = c(0.9666667, 0.9666667, 0.0333333),
  "pref_inf_diff_congruent" =  c(0.3583333, 0.3583333, 0.6416667),
  "pref_inf_diff_incongruent" = c(0.6416667, 0.6416667, 0.3583333),
  "novel_inf_same_congruent" =  c(0.1666667, 0.1666667, 0.8333333),
  "novel_inf_same_incongruent" = c(0.8333333, 0.8333333, 0.1666667),
  "novel_inf_diff_congruent" =  c(0.4083333, 0.4083333, 0.5916667),
  "novel_inf_diff_incongruent" = c(0.5916667, 0.5916667, 0.4083333)
)




# get model predictions from webppl
wp.rs.all <- data.frame()
for (conditionName in names(priorProbsFromR)) {
  
  priorProbs <- priorProbsFromR[[conditionName]]
  rs.wp <- webppl(
    program_code = paste(rsaUtils, rsaModel, sep='\n'),
    data = priorProbs,
    data_var = "priorProbs"
  )
  wp.rs.all <- bind_rows(
    wp.rs.all, 
    rs.wp %>% 
      mutate(condition = conditionName,
             Model = "Full model")
  )
}


# common confition names to join by
con <- c("pref_inf_same_congruent",
  "pref_inf_same_incongruent",
  "pref_inf_diff_congruent",
  "pref_inf_diff_incongruent",
  "novel_inf_same_congruent",
  "novel_inf_same_incongruent",
  "novel_inf_diff_congruent",
  "novel_inf_diff_incongruent")

#Model predictions from prior only model
prior_only <- predictions %>%
  filter(Model == "Prior only")%>%
  mutate(condition = con)

#Model predictions from no prior model
no_prior <- predictions %>%
  filter(Model == "No prior")%>%
  mutate(condition = con)

# summarizing the data
data.summary <- data %>%
  mutate(condition = paste(experiment,change, alignment, sep = "_")) %>%
  group_by(condition) %>%
  summarize(n= n(),
            k = sum(correct_inf))

# joining model predictions and data
model_comparison <- rbind(
  left_join(
  wp.rs.all %>% filter(obj == "circle")%>%mutate(exp = substr(condition,1,4)) %>%select(condition,exp,Model,prob),
  data.summary),
  left_join(
  no_prior%>%mutate(prob = corr, exp = substr(condition,1,4))%>%select(condition,exp,Model,prob),
  data.summary),
  left_join(
  prior_only%>%mutate(prob = corr, exp = substr(condition,1,4))%>%select(condition,exp,Model,prob),
  data.summary)
  )

# calculate how well model predicts data
comp_model<- model_comparison%>%
  mutate(p_data_given_model = dbinom(size = n, p = prob, x = k, log = T)) %>%
  group_by(Model) %>%
  summarize(log_p_data_given_model = sum(p_data_given_model))

comp_model

## log p (data | model)
## bayes factor_1,2 = p (data | model_1) / p (data | model_2)
## log bf = log p (data | model_1) - log p (data | model_2)

# Bayes factors full vs other models
bf_full_no_prior <- exp((comp_model[1,2] - comp_model[2,2]))
bf_full_no_prior

bf_full_prior_only <- exp((comp_model[1,2] - comp_model[3,2]))
bf_full_prior_only

# model comparison by experiment
comp_model_by_exp<- model_comparison%>%
  mutate(p_data_given_model = dbinom(size = n, p = prob, x = k, log = T)) %>%
  group_by(Model,exp) %>%
  summarize(log_p_data_given_model = sum(p_data_given_model))

# Bayes factors full - prior only
pref_bf_full_prior_only <- exp(comp_model_by_exp[2,3] - comp_model_by_exp[6,3])
pref_bf_full_prior_only

novel_bf_full_prior_only <- exp(comp_model_by_exp[1,3] - comp_model_by_exp[5,3])
novel_bf_full_prior_only

```

At what ratio does it flip back to more informative?

```{r , echo=FALSE}

pred <- data.frame(
  Prior = c("90/10","80/20","70/30","60/40","50/50"),
  corr = c(0.1118794400899893,0.24897738407515466,0.40911964439987003,0.5807810413750243,0.74)
)

ggplot(pred, 
       aes(x = Prior, y = corr, fill = Prior)) +
  geom_bar(stat="identity") + 
  geom_hline(yintercept = 0.5, lty=2)+
  labs(x="",y="Proportion Choosing More Informative")+
  theme_few(base_size = 12) +
  scale_fill_discrete(name = "Prior: less inf / more inf")+
  ylim(0,1)+
  theme(axis.text.x=element_blank(),axis.ticks.x=element_blank())

```